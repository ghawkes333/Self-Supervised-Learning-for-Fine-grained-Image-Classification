{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SimCLR model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "from torchvision.models import resnet18\n",
    "import argparse\n",
    "import cv2\n",
    "import numpy as np\n",
    "from torch.autograd import Function\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import models, transforms\n",
    "\n",
    "class SimCLR(nn.Module):\n",
    "    def __init__(self, out_dim):\n",
    "        super(SimCLR, self).__init__()\n",
    "        resnet = resnet18()\n",
    "        res_out_dim = resnet.fc.in_features\n",
    "        self.f = nn.Sequential(*list(resnet.children())[:-1])\n",
    "        self.g = nn.Sequential(nn.Linear(res_out_dim, res_out_dim), nn.ReLU(), nn.Linear(res_out_dim, out_dim))\n",
    "\n",
    "    def forward(self, xi, xj):\n",
    "        x = torch.cat([xi, xj], dim=0)\n",
    "        h = self.f(x)\n",
    "        z = self.g(h.squeeze())\n",
    "        return h, z\n",
    "\n",
    "    def get_hidden(self, x):\n",
    "        h = self.f(x)\n",
    "        return h.squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SimCLR model with classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomModel, self).__init__()\n",
    "        proj_dim = 512\n",
    "        hidden_dim = 256\n",
    "        self.encoder = SimCLR(out_dim=proj_dim)\n",
    "        ckpt = torch.load('model_3x3_DCL.ckpt')\n",
    "        \n",
    "        #print(\"Load checkpoint trained for %d epochs. Loss is %f.\" %(ckpt[\"epoch\"], ckpt[\"loss\"]))\n",
    "        (self.encoder).load_state_dict(ckpt[\"model\"])\n",
    "        self.fc = nn.Sequential(nn.Linear(proj_dim, hidden_dim), nn.ReLU(), nn.Linear(hidden_dim, 5))\n",
    "\n",
    "    def forward(self,x):\n",
    "        \n",
    "        out = self.encoder.get_hidden(x)\n",
    "        out = self.fc(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Print class prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load checkpoint trained for 373 epochs. Loss is 3.153403.\n",
      "cgm\n"
     ]
    }
   ],
   "source": [
    "model = CustomModel().to('cuda')\n",
    "device = 'cuda' if torch.cuda.is_available else 'cpu'\n",
    "ckpt = torch.load('fullmodel_dcl.ckpt') #replace model name here\n",
    "model.load_state_dict(ckpt[\"model\"])\n",
    "img_transform = transforms.Compose([transforms.Resize(size=(512,512)), transforms.ToTensor()])\n",
    "dataset = datasets.ImageFolder(root='tester2',transform=img_transform)\n",
    "test_loader = DataLoader(dataset, batch_size=1, drop_last=True, num_workers=8, shuffle=True)\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for test_x, _ in test_loader:\n",
    "        test_x = test_x.to(device)\n",
    "        h = model.encoder.get_hidden(test_x)\n",
    "        logits = model.fc(h)\n",
    "        pred = torch.argmax(logits)\n",
    "        if(pred == 0):\n",
    "            print('cbb')\n",
    "        elif (pred == 1):\n",
    "            print('cbsd')\n",
    "        elif (pred == 2):\n",
    "            print('cgm')\n",
    "        elif (pred == 3):\n",
    "            print('cmd')\n",
    "        else:\n",
    "            print('healthy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grad-CAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load checkpoint trained for 373 epochs. Loss is 3.153403.\n"
     ]
    }
   ],
   "source": [
    "class FeatureExtractor():\n",
    "    \"\"\" Class for extracting activations and\n",
    "    registering gradients from targetted intermediate layers \"\"\"\n",
    "\n",
    "    def __init__(self, model, target_layers):\n",
    "        self.model = model\n",
    "        self.target_layers = target_layers\n",
    "        self.gradients = []\n",
    "\n",
    "    def save_gradient(self, grad):\n",
    "        self.gradients.append(grad)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        outputs = []\n",
    "        self.gradients = []\n",
    "        for name, module in self.model._modules.items():\n",
    "            x = module(x)\n",
    "            if name in self.target_layers:\n",
    "                x.register_hook(self.save_gradient)\n",
    "                outputs += [x]\n",
    "        return outputs, x.squeeze()\n",
    "\n",
    "class ModelOutputs():\n",
    "    \"\"\" Class for making a forward pass, and getting:\n",
    "    1. The network output.\n",
    "    2. Activations from intermeddiate targetted layers.\n",
    "    3. Gradients from intermeddiate targetted layers. \"\"\"\n",
    "\n",
    "    def __init__(self, model, feature_module, target_layers):\n",
    "        self.model = model\n",
    "        self.feature_module = feature_module\n",
    "        self.feature_extractor = FeatureExtractor(self.feature_module, target_layers)\n",
    "\n",
    "    def get_gradients(self):\n",
    "        return self.feature_extractor.gradients\n",
    "\n",
    "    def __call__(self, x):\n",
    "        target_activations = []\n",
    "        for name, module in self.model._modules.items():\n",
    "            if \"avgpool\" in name.lower():\n",
    "                x = module(x)\n",
    "                x = x.view(x.size(0),-1)\n",
    "            elif \"encoder\" in name.lower():\n",
    "                target_activations, x = self.feature_extractor(x)\n",
    "            else:\n",
    "                x = module(x)\n",
    "        \n",
    "        #print(x)\n",
    "        return target_activations, x\n",
    "\n",
    "def preprocess_image(img):\n",
    "    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "    preprocessing = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ])\n",
    "    return preprocessing(img.copy()).unsqueeze(0)\n",
    "\n",
    "def show_cam_on_image(img, mask):\n",
    "    heatmap = cv2.applyColorMap(np.uint8(255 * mask), cv2.COLORMAP_JET)\n",
    "    heatmap = np.float32(heatmap) / 255\n",
    "    cam = heatmap + np.float32(img)\n",
    "    cam = cam / np.max(cam)\n",
    "    return np.uint8(255 * cam)\n",
    "\n",
    "class GradCam:\n",
    "    def __init__(self, model, feature_module, target_layer_names, use_cuda):\n",
    "        self.model = model\n",
    "        self.feature_module = feature_module\n",
    "        self.model.eval()\n",
    "        self.cuda = use_cuda\n",
    "        if self.cuda:\n",
    "            self.model = model.cuda()\n",
    "\n",
    "        self.extractor = ModelOutputs(self.model, self.feature_module, target_layer_names)\n",
    "\n",
    "    def forward(self, input_img):\n",
    "        return self.model(input_img)\n",
    "\n",
    "    def __call__(self, input_img, target_category=None):\n",
    "        if self.cuda:\n",
    "            input_img = input_img.cuda()\n",
    "\n",
    "        features, output = self.extractor(input_img)\n",
    "\n",
    "        if target_category == None:\n",
    "            target_category = np.argmax(output.cpu().data.numpy())\n",
    "\n",
    "        one_hot = np.zeros((1, output.size()[-1]), dtype=np.float32)\n",
    "        one_hot[0][target_category] = 1\n",
    "        one_hot = torch.from_numpy(one_hot).requires_grad_(True)\n",
    "        if self.cuda:\n",
    "            one_hot = one_hot.cuda()\n",
    "        \n",
    "        one_hot = torch.sum(one_hot * output)\n",
    "\n",
    "        self.feature_module.zero_grad()\n",
    "        self.model.zero_grad()\n",
    "        one_hot.backward(retain_graph=True)\n",
    "\n",
    "        grads_val = self.extractor.get_gradients()[-1].cpu().data.numpy()\n",
    "\n",
    "        target = features[-1]\n",
    "        target = target.cpu().data.numpy()[0, :]\n",
    "\n",
    "        weights = np.mean(grads_val, axis=(2, 3))[0, :]\n",
    "        cam = np.zeros(target.shape[1:], dtype=np.float32)\n",
    "\n",
    "        for i, w in enumerate(weights):\n",
    "            cam += w * target[i, :, :]\n",
    "\n",
    "        cam = np.maximum(cam, 0)\n",
    "        cam = cv2.resize(cam, input_img.shape[2:])\n",
    "        cam = cam - np.min(cam)\n",
    "        cam = cam / np.max(cam)\n",
    "        return cam\n",
    "\n",
    "\n",
    "class GuidedBackpropReLU(Function):\n",
    "    @staticmethod\n",
    "    def forward(self, input_img):\n",
    "        positive_mask = (input_img > 0).type_as(input_img)\n",
    "        output = torch.addcmul(torch.zeros(input_img.size()).type_as(input_img), input_img, positive_mask)\n",
    "        self.save_for_backward(input_img, output)\n",
    "        return output\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(self, grad_output):\n",
    "        input_img, output = self.saved_tensors\n",
    "        grad_input = None\n",
    "\n",
    "        positive_mask_1 = (input_img > 0).type_as(grad_output)\n",
    "        positive_mask_2 = (grad_output > 0).type_as(grad_output)\n",
    "        grad_input = torch.addcmul(torch.zeros(input_img.size()).type_as(input_img),\n",
    "                                   torch.addcmul(torch.zeros(input_img.size()).type_as(input_img), grad_output,\n",
    "                                                 positive_mask_1), positive_mask_2)\n",
    "        return grad_input\n",
    "\n",
    "\n",
    "class GuidedBackpropReLUModel:\n",
    "    def __init__(self, model, use_cuda):\n",
    "        self.model = model\n",
    "        self.model.eval()\n",
    "        self.cuda = use_cuda\n",
    "        if self.cuda:\n",
    "            self.model = model.cuda()\n",
    "\n",
    "        def recursive_relu_apply(module_top):\n",
    "            for idx, module in module_top._modules.items():\n",
    "                recursive_relu_apply(module)\n",
    "                if module.__class__.__name__ == 'ReLU':\n",
    "                    module_top._modules[idx] = GuidedBackpropReLU.apply\n",
    "\n",
    "        # replace ReLU with GuidedBackpropReLU\n",
    "        recursive_relu_apply(self.model)\n",
    "\n",
    "    def forward(self, input_img):\n",
    "        return self.model(input_img)\n",
    "\n",
    "    def __call__(self, input_img, target_category=None):\n",
    "        if self.cuda:\n",
    "            input_img = input_img.cuda()\n",
    "\n",
    "        input_img = input_img.requires_grad_(True)\n",
    "\n",
    "        output = self.forward(input_img)\n",
    "\n",
    "        if target_category == None:\n",
    "            target_category = np.argmax(output.cpu().data.numpy())\n",
    "\n",
    "        one_hot = np.zeros((1, output.size()[-1]), dtype=np.float32)\n",
    "        one_hot[0][target_category] = 1\n",
    "        one_hot = torch.from_numpy(one_hot).requires_grad_(True)\n",
    "        if self.cuda:\n",
    "            one_hot = one_hot.cuda()\n",
    "\n",
    "        one_hot = torch.sum(one_hot * output)\n",
    "        one_hot.backward(retain_graph=True)\n",
    "\n",
    "        output = input_img.grad.cpu().data.numpy()\n",
    "        output = output[0, :, :, :]\n",
    "\n",
    "        return output\n",
    "\n",
    "def get_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--use-cuda', action='store_true', default=False,\n",
    "                        help='Use NVIDIA GPU acceleration')\n",
    "    parser.add_argument('--image-path', type=str, default='./examples/both.png',\n",
    "                        help='Input image path')\n",
    "    args = parser.parse_args()\n",
    "    args.use_cuda = args.use_cuda and torch.cuda.is_available()\n",
    "    if args.use_cuda:\n",
    "        print(\"Using GPU for acceleration\")\n",
    "    else:\n",
    "        print(\"Using CPU for computation\")\n",
    "\n",
    "    return args\n",
    "\n",
    "def deprocess_image(img):\n",
    "    \"\"\" see https://github.com/jacobgil/keras-grad-cam/blob/master/grad-cam.py#L65 \"\"\"\n",
    "    img = img - np.mean(img)\n",
    "    img = img / (np.std(img) + 1e-5)\n",
    "    img = img * 0.1\n",
    "    img = img + 0.5\n",
    "    img = np.clip(img, 0, 1)\n",
    "    return np.uint8(img*255)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \"\"\" python grad_cam.py <path_to_image>\n",
    "    1. Loads an image with opencv.\n",
    "    2. Preprocesses it for ResNet50 and converts to a pytorch variable.\n",
    "    3. Makes a forward pass to find the category index with the highest score,\n",
    "    and computes intermediate activations.\n",
    "    Makes the visualization. \"\"\"\n",
    "    \n",
    "    model = CustomModel()\n",
    "    ckpt = torch.load('fullmodel_DCL7.ckpt')\n",
    "    model.load_state_dict(ckpt[\"model\"])\n",
    "    \n",
    "    grad_cam = GradCam(model=model, feature_module=model.encoder.f, \\\n",
    "                       target_layer_names=[\"7\"], use_cuda=True)\n",
    "    \n",
    "    ######### Change name of image here    \n",
    "    img = cv2.imread('test/unknown/train-cgm-490.jpg', 1) \n",
    "    \n",
    "    img = np.float32(img) / 255\n",
    "    # Opencv loads as BGR:\n",
    "    img = img[:, :, ::-1]\n",
    "    input_img = preprocess_image(img)\n",
    "\n",
    "    # If None, returns the map for the highest scoring category.\n",
    "    # Otherwise, targets the requested category.\n",
    "    target_category = None\n",
    "    grayscale_cam = grad_cam(input_img, target_category)\n",
    "\n",
    "    grayscale_cam = cv2.resize(grayscale_cam, (img.shape[1], img.shape[0]))\n",
    "    cam = show_cam_on_image(img, grayscale_cam)\n",
    "\n",
    "    gb_model = GuidedBackpropReLUModel(model=model, use_cuda=True)\n",
    "    gb = gb_model(input_img, target_category=target_category)\n",
    "    gb = gb.transpose((1, 2, 0))\n",
    "\n",
    "    cam_mask = cv2.merge([grayscale_cam, grayscale_cam, grayscale_cam])\n",
    "    cam_gb = deprocess_image(cam_mask*gb)\n",
    "    gb = deprocess_image(gb)\n",
    "\n",
    "    cv2.imwrite(\"CAM.jpg\", cam)\n",
    "    cv2.imwrite('cam_gb.jpg', cam_gb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
