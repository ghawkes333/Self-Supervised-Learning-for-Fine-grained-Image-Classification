{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SimCLR transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "np.random.seed(0)\n",
    "\n",
    "\n",
    "class GaussianBlur(object):\n",
    "    # Implements Gaussian blur as described in the SimCLR paper\n",
    "    def __init__(self, kernel_size, min=0.1, max=2.0):\n",
    "        self.min = min\n",
    "        self.max = max\n",
    "        # kernel size is set to be 10% of the image height/width\n",
    "        self.kernel_size = kernel_size\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        sample = np.array(sample)\n",
    "\n",
    "        # blur the image with a 50% chance\n",
    "        prob = np.random.random_sample()\n",
    "\n",
    "        if prob < 0.5:\n",
    "            sigma = (self.max - self.min) * np.random.random_sample() + self.min\n",
    "            sample = cv2.GaussianBlur(sample, (self.kernel_size, self.kernel_size), sigma)\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets\n",
    "from PIL import Image\n",
    "import random\n",
    "\n",
    "class DataSetWrapper(object):\n",
    "    def __init__(self, batch_size, num_workers, valid_size, input_shape, strength):\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "        self.valid_size = valid_size\n",
    "        self.input_shape = input_shape\n",
    "        self.strength = strength\n",
    "\n",
    "    def get_data_loaders(self):\n",
    "        data_augment = self._simclr_transform()\n",
    "        train_dataset = datasets.ImageFolder(root='extra/',\n",
    "                                               transform=SimCLRDataTransform(data_augment))\n",
    "        \n",
    "        train_loader, valid_loader = self.get_train_validation_data_loaders(train_dataset)\n",
    "        return train_loader, valid_loader \n",
    "\n",
    "    def _simclr_transform(self):\n",
    "        \n",
    "        data_transforms: transforms.Compose\n",
    "\n",
    "        s = self.strength # color distortion strength\n",
    "        color_jitter = transforms.ColorJitter(0.8*s, 0.8*s, 0.8*s, 0.2*s)\n",
    "        gaussian_blur = GaussianBlur(kernel_size = int(0.1* self.input_shape[0]))\n",
    "        \n",
    "        data_transforms = transforms.Compose([\n",
    "            transforms.Reszie((512,512)),\n",
    "            transforms.RandomApply([color_jitter], p=0.4), # Random color distortions\n",
    "            transforms.RandomGrayscale(p=0.2),\n",
    "            transforms.ToTensor()\n",
    "        ])\n",
    "\n",
    "        return data_transforms\n",
    "\n",
    "    def get_train_validation_data_loaders(self, train_dataset):\n",
    "        # obtain training indices that will be used for validation\n",
    "        num_train = len(train_dataset)\n",
    "        indices = list(range(num_train))\n",
    "        np.random.shuffle(indices)\n",
    "\n",
    "        split = int(np.floor(self.valid_size * num_train))\n",
    "        train_idx, valid_idx = indices[split:], indices[:split]\n",
    "\n",
    "        # define samplers for obtaining training and validation batches\n",
    "        train_sampler = SubsetRandomSampler(train_idx)\n",
    "        valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "\n",
    "        train_loader = DataLoader(train_dataset, batch_size=self.batch_size, sampler=train_sampler,\n",
    "                                  num_workers=self.num_workers, drop_last=True, shuffle=False)\n",
    "\n",
    "        valid_loader = DataLoader(train_dataset, batch_size=self.batch_size, sampler=valid_sampler,\n",
    "                                  num_workers=self.num_workers, drop_last=True)\n",
    "        return train_loader, valid_loader\n",
    "\n",
    "\n",
    "class SimCLRDataTransform(object):\n",
    "    def __init__(self, transform):\n",
    "        self.transform = transform\n",
    "    \n",
    "    #Credits: https://github.com/JDAI-CV/DCL\n",
    "    #DCL based jigsaw patch shuffling\n",
    "    def swap(self,img, crop):\n",
    "        def crop_image(image, cropnum):\n",
    "            width, high = image.size\n",
    "            crop_x = [int((width / cropnum[0]) * i) for i in range(cropnum[0] + 1)]\n",
    "            crop_y = [int((high / cropnum[1]) * i) for i in range(cropnum[1] + 1)]\n",
    "            im_list = []\n",
    "            for j in range(len(crop_y) - 1):\n",
    "                for i in range(len(crop_x) - 1):\n",
    "                    im_list.append(image.crop((crop_x[i], crop_y[j], min(crop_x[i + 1], width), min(crop_y[j + 1], high))))\n",
    "            return im_list\n",
    "\n",
    "        widthcut, highcut = img.size\n",
    "        img = img.crop((10, 10, widthcut-10, highcut-10))\n",
    "        images = crop_image(img, crop)\n",
    "        pro = 5\n",
    "        if pro >= 5:          \n",
    "            tmpx = []\n",
    "            tmpy = []\n",
    "            count_x = 0\n",
    "            count_y = 0\n",
    "            k = 1\n",
    "            RAN = 2\n",
    "            for i in range(crop[1] * crop[0]):\n",
    "                tmpx.append(images[i])\n",
    "                count_x += 1\n",
    "                #ensuring shuffling only in neighboring patch\n",
    "                if len(tmpx) >= k:\n",
    "                    tmp = tmpx[count_x - RAN:count_x]\n",
    "                    random.shuffle(tmp)\n",
    "                    tmpx[count_x - RAN:count_x] = tmp\n",
    "                if count_x == crop[0]:\n",
    "                    tmpy.append(tmpx)\n",
    "                    count_x = 0\n",
    "                    count_y += 1\n",
    "                    tmpx = []\n",
    "                if len(tmpy) >= k:\n",
    "                    tmp2 = tmpy[count_y - RAN:count_y]\n",
    "                    random.shuffle(tmp2)\n",
    "                    tmpy[count_y - RAN:count_y] = tmp2\n",
    "            random_im = []\n",
    "            for line in tmpy:\n",
    "                random_im.extend(line)\n",
    "        \n",
    "            width, high = img.size\n",
    "            iw = int(width / crop[0])\n",
    "            ih = int(high / crop[1])\n",
    "            toImage = Image.new('RGB', (iw * crop[0], ih * crop[1]))\n",
    "            x = 0\n",
    "            y = 0\n",
    "            for i in random_im:\n",
    "                i = i.resize((iw, ih), Image.ANTIALIAS)\n",
    "                toImage.paste(i, (x * iw, y * ih))\n",
    "                x += 1\n",
    "                if x == crop[0]:\n",
    "                    x = 0\n",
    "                    y += 1\n",
    "        else:\n",
    "            toImage = img\n",
    "        toImage = toImage.resize((widthcut, highcut))\n",
    "        return toImage\n",
    "    \n",
    "    #applying transforms\n",
    "    def __call__(self, sample):\n",
    "\n",
    "        sample2 = self.swap(sample,(7,7)) #change size here for different jigsaw size\n",
    "        xi = self.transform(sample2)\n",
    "        xj = self.transform(sample)\n",
    "        return xi, xj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SimCLR model\n",
    "Credit: https://github.com/ssumin6/SimCLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "class SimCLR(nn.Module):\n",
    "    def __init__(self, out_dim):\n",
    "        super(SimCLR, self).__init__()\n",
    "        resnet = resnet18()\n",
    "        res_out_dim = resnet.fc.in_features\n",
    "        #resnet encoder\n",
    "        self.f = nn.Sequential(*list(resnet.children())[:-1])\n",
    "        #non linear projection head\n",
    "        self.g = nn.Sequential(nn.Linear(res_out_dim, res_out_dim), nn.ReLU(), nn.Linear(res_out_dim, out_dim))\n",
    "\n",
    "    def forward(self, xi, xj):\n",
    "        x = torch.cat([xi, xj], dim=0)\n",
    "        h = self.f(x)\n",
    "        z = self.g(h.squeeze())\n",
    "        return h, z\n",
    "\n",
    "    def get_hidden(self, x):\n",
    "        h = self.f(x)\n",
    "        return h.squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SimCLR training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import argparse\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def main():\n",
    "    device = 'cuda' if torch.cuda.is_available else 'cpu'\n",
    "\n",
    "    ### Hyperparameters setting ###\n",
    "    epochs = 500\n",
    "    batch_size = 64\n",
    "    T = 0.5\n",
    "    proj_dim = 512\n",
    "    num_worker = 8\n",
    "    valid_size = 0.2\n",
    "    strength = 1.0\n",
    "    trainloss = []\n",
    "    valloss = []\n",
    "\n",
    "    ### DataLoader ###\n",
    "    dataset = DataSetWrapper(batch_size, num_worker , valid_size, input_shape = (512,512, 3), strength=strength)\n",
    "    train_loader , valid_loader = dataset.get_data_loaders()\n",
    "\n",
    "    model = SimCLR(out_dim=proj_dim).to(device)\n",
    "\n",
    "    ### Optimizer & scheduler ###\n",
    "    optimizer = torch.optim.Adam(model.parameters(), 1e-3, weight_decay=1e-5)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=len(train_loader), eta_min=0, last_epoch=-1)\n",
    "\n",
    "    '''\n",
    "    Model-- ResNet18(encoder network) + MLP with one hidden layer(projection head)\n",
    "    Loss -- NT-Xent Loss\n",
    "    '''\n",
    "    val_loss = 1e9\n",
    "    \n",
    "    #Loss function\n",
    "    def NTXent(z, N):\n",
    "        z = F.normalize(z, dim=1)\n",
    "        mask = torch.eye(N*2).to(device).bool()\n",
    "        tmp = torch.mm(z, z.T).masked_fill(mask, float('-inf'))\n",
    "        loss_matrix = - F.log_softmax(tmp / T, dim=1) \n",
    "        loss = sum(torch.diag(loss_matrix[:N, N:]))+sum(torch.diag(loss_matrix[N:, :N]))\n",
    "        loss /= 2 * N\n",
    "        return loss\n",
    "\n",
    "    def train(xi, xj):\n",
    "        xi, xj = xi.to(device), xj.to(device)\n",
    "        h, z = model(xi, xj)\n",
    "        optimizer.zero_grad()\n",
    "        loss = NTXent(z, xi.shape[0])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        return loss\n",
    "\n",
    "    def valid(xi, xj):\n",
    "        xi, xj = xi.to(device), xj.to(device)\n",
    "        h, z = model(xi, xj)\n",
    "        loss = NTXent(z, xi.shape[0])\n",
    "        return loss\n",
    "    \n",
    "    print('started train')\n",
    "    #Training and validation\n",
    "    for epoch in range(epochs):\n",
    "        start = time.time()\n",
    "        for (xi, xj),_ in train_loader:\n",
    "            loss = train(xi, xj)\n",
    "        print(\"[Epoch %d] Train Loss %f. Time takes %s\" %(epoch, loss, time.time()-start))\n",
    "        trainloss.append(loss)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            losses = []\n",
    "            for (val_xi, val_xj),_ in valid_loader:\n",
    "                losses.append(valid(val_xi, val_xj))\n",
    "            loss = sum(losses) / len(losses)\n",
    "            valloss.append(loss)\n",
    "            print(\"[Epoch %d] Valid Loss %f\" %(epoch, loss))\n",
    "            \n",
    "            if (loss < val_loss):\n",
    "                val_loss = loss\n",
    "                torch.save({\"model\": model.state_dict(), \"epoch\": epoch, \"loss\": loss}, \"model_trial.ckpt\")\n",
    "                \n",
    "    eps = range(1, len(trainloss) + 1)\n",
    "    plt.plot(eps, trainloss, 'b', label='Training Accuracy')\n",
    "    plt.plot(eps, valloss, 'r', label='Validation Accuracy')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "    plt.legend()\n",
    "    plt.savefig('Simclr_acc_plot.png')\n",
    "            \n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Attaching classifier to Resnet encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "\n",
    "#Creating custom model by attaching classifier to SimCLR encoder\n",
    "\n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomModel, self).__init__()\n",
    "        proj_dim = 512\n",
    "        hidden_dim = 256\n",
    "        self.encoder = SimCLR(out_dim=proj_dim)\n",
    "        ckpt = torch.load('model_trial.ckpt')\n",
    "        print(\"Load checkpoint trained for %d epochs. Loss is %f.\" %(ckpt[\"epoch\"], ckpt[\"loss\"]))\n",
    "        (self.encoder).load_state_dict(ckpt[\"model\"])\n",
    "        self.fc = nn.Sequential(nn.Linear(proj_dim, hidden_dim), nn.ReLU(), nn.Linear(hidden_dim, 5))\n",
    "\n",
    "    def forward(self,x):\n",
    "        \n",
    "        out = self.encoder.get_hidden(x)\n",
    "        out = self.fc(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downstream task training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import argparse\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.models import resnet18\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def evaluate(test_loader, model, device):\n",
    "    correct = 0    \n",
    "    total = 0\n",
    "    confusion_matrix = torch.zeros(5,5)\n",
    "    model.eval()\n",
    "    \n",
    "    #Prints confusion matrix\n",
    "    with torch.no_grad():\n",
    "        for test_x, test_y in test_loader:\n",
    "            test_x, test_y = test_x.to(device), test_y.to(device) \n",
    "            h = model.encoder.get_hidden(test_x)\n",
    "            logits = model.fc(h)\n",
    "              \n",
    "            pred = torch.argmax(logits, dim=1)\n",
    "            total += test_y.shape[0]\n",
    "            correct += (pred == test_y).sum().item()\n",
    "            for l, p in zip(test_y.view(-1), pred.view(-1)):\n",
    "                confusion_matrix[l.long(), p.long()] += 1\n",
    "                \n",
    "    total_acc = 100.0 * correct / total\n",
    "    print(confusion_matrix)\n",
    "    return total_acc\n",
    "\n",
    "def main2():\n",
    "    device = 'cuda' if torch.cuda.is_available else 'cpu'\n",
    "\n",
    "    ## Hyperparameters\n",
    "    finetune = True \n",
    "    proj_dim = 512\n",
    "    hidden_dim = 256\n",
    "\n",
    "    model = CustomModel().to(device)\n",
    "    \n",
    "    img_transform = transforms.Compose([transforms.Resize(size=(512,512)), transforms.ToTensor()])\n",
    "    train_dataset = datasets.ImageFolder(root='train_combined',transform=img_transform)\n",
    "    \n",
    "    num_train = len(train_dataset)\n",
    "    indices = list(range(num_train))\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "    split = int(np.floor(0.2 * num_train))\n",
    "    train_idx, valid_idx = indices[split:], indices[:split]\n",
    "\n",
    "    # define samplers for obtaining training and validation batches\n",
    "    train_sampler = SubsetRandomSampler(train_idx)\n",
    "        \n",
    "    valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=16,sampler=train_sampler,num_workers=8, drop_last=True, shuffle=False)\n",
    "\n",
    "    test_loader = DataLoader(train_dataset, batch_size=16,sampler=valid_sampler,num_workers=8, drop_last=True)\n",
    "    n_classes = 5\n",
    "\n",
    "    # Freeze encoder network\n",
    "    if finetune:\n",
    "        for p in model.encoder.f.parameters():\n",
    "            p.requires_grad = False\n",
    "\n",
    "    optimizer = torch.optim.Adam(list(model.encoder.f.parameters())+list(model.fc.parameters()), lr=3e-04) \n",
    "    \n",
    "    target_acc = 0.0 \n",
    "    token = 0 # For early stopping\n",
    "    trainAcc = []\n",
    "    valAcc = []\n",
    "    \n",
    "    # Train Linear Classifier\n",
    "    for epoch in range(100):\n",
    "        start = time.time()\n",
    "        t_total = 0\n",
    "        t_correct = 0\n",
    "        for x, y in train_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            h = model.encoder.get_hidden(x)\n",
    "            logits = model.fc(h)\n",
    "            \n",
    "            pred = torch.argmax(logits, dim=1)\n",
    "            t_total += y.shape[0]\n",
    "            t_correct += (pred == y).sum().item()           \n",
    "            \n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss = F.cross_entropy(logits, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        trainAcc.append(100.0 * t_correct / t_total)\n",
    "        correct = 0    \n",
    "        total = 0\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for test_x, test_y in test_loader:\n",
    "                test_x, test_y = test_x.to(device), test_y.to(device) \n",
    "                h = model.encoder.get_hidden(test_x)\n",
    "                logits = model.fc(h)\n",
    "              \n",
    "                pred = torch.argmax(logits, dim=1)\n",
    "                total += test_y.shape[0]\n",
    "                correct += (pred == test_y).sum().item()\n",
    "        valid_acc = 100.0 * correct / total\n",
    "        valAcc.append(valid_acc)\n",
    "        \n",
    "        print(\"[Epoch %2d] Valid Acc %f. Time takes %s\" %(epoch, valid_acc, time.time()-start))\n",
    "        if (valid_acc > target_acc):\n",
    "            target_acc = valid_acc\n",
    "            torch.save({\"model\": model.state_dict(), \"epoch\": epoch, \"loss\": loss}, \"fullmodel_trial.ckpt\")\n",
    "            token = 0 \n",
    "        elif token >= 5:\n",
    "            print(\"Early Stop at Epoch %d.\" %(epoch))\n",
    "            break\n",
    "        else:\n",
    "            token += 1\n",
    "\n",
    "    # Evaluate\n",
    "    eps = range(1, len(trainAcc) + 1)\n",
    "    plt.plot(eps, trainAcc, 'b', label='Training Accuracy')\n",
    "    plt.plot(eps, valAcc, 'r', label='Validation Accuracy')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "    plt.legend()\n",
    "    plt.savefig('Simclr_acc_trial.png')\n",
    "    acc = evaluate(test_loader, model, device)\n",
    "\n",
    "main2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Grad-CAM\n",
    "Credits: https://github.com/yaleCat/Grad-CAM-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import argparse\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.autograd import Function\n",
    "from torchvision import models, transforms\n",
    "\n",
    "\n",
    "#Generates Grad-CAM for an input image\n",
    "\n",
    "class FeatureExtractor():\n",
    "    \"\"\" Class for extracting activations and\n",
    "    registering gradients from targetted intermediate layers \"\"\"\n",
    "\n",
    "    def __init__(self, model, target_layers):\n",
    "        self.model = model\n",
    "        self.target_layers = target_layers\n",
    "        self.gradients = []\n",
    "\n",
    "    def save_gradient(self, grad):\n",
    "        self.gradients.append(grad)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        outputs = []\n",
    "        self.gradients = []\n",
    "        for name, module in self.model._modules.items():\n",
    "            x = module(x)\n",
    "            if name in self.target_layers:\n",
    "                x.register_hook(self.save_gradient)\n",
    "                outputs += [x]\n",
    "        return outputs, x.squeeze()\n",
    "\n",
    "class ModelOutputs():\n",
    "    \"\"\" Class for making a forward pass, and getting:\n",
    "    1. The network output.\n",
    "    2. Activations from intermeddiate targetted layers.\n",
    "    3. Gradients from intermeddiate targetted layers. \"\"\"\n",
    "\n",
    "    def __init__(self, model, feature_module, target_layers):\n",
    "        self.model = model\n",
    "        self.feature_module = feature_module\n",
    "        self.feature_extractor = FeatureExtractor(self.feature_module, target_layers)\n",
    "\n",
    "    def get_gradients(self):\n",
    "        return self.feature_extractor.gradients\n",
    "\n",
    "    def __call__(self, x):\n",
    "        target_activations = []\n",
    "        for name, module in self.model._modules.items():\n",
    "            if \"avgpool\" in name.lower():\n",
    "                x = module(x)\n",
    "                x = x.view(x.size(0),-1)\n",
    "            elif \"encoder\" in name.lower():\n",
    "                target_activations, x = self.feature_extractor(x)\n",
    "            else:\n",
    "                x = module(x)\n",
    "        \n",
    "        return target_activations, x\n",
    "\n",
    "def preprocess_image(img):\n",
    "    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "    preprocessing = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ])\n",
    "    return preprocessing(img.copy()).unsqueeze(0)\n",
    "\n",
    "def show_cam_on_image(img, mask):\n",
    "    heatmap = cv2.applyColorMap(np.uint8(255 * mask), cv2.COLORMAP_JET)\n",
    "    heatmap = np.float32(heatmap) / 255\n",
    "    cam = heatmap + np.float32(img)\n",
    "    cam = cam / np.max(cam)\n",
    "    return np.uint8(255 * cam)\n",
    "\n",
    "class GradCam:\n",
    "    def __init__(self, model, feature_module, target_layer_names, use_cuda):\n",
    "        self.model = model\n",
    "        self.feature_module = feature_module\n",
    "        self.model.eval()\n",
    "        self.cuda = use_cuda\n",
    "        if self.cuda:\n",
    "            self.model = model.cuda()\n",
    "\n",
    "        self.extractor = ModelOutputs(self.model, self.feature_module, target_layer_names)\n",
    "\n",
    "    def forward(self, input_img):\n",
    "        return self.model(input_img)\n",
    "\n",
    "    def __call__(self, input_img, target_category=None):\n",
    "        if self.cuda:\n",
    "            input_img = input_img.cuda()\n",
    "\n",
    "        features, output = self.extractor(input_img)\n",
    "\n",
    "        if target_category == None:\n",
    "            target_category = np.argmax(output.cpu().data.numpy())\n",
    "\n",
    "        one_hot = np.zeros((1, output.size()[-1]), dtype=np.float32)\n",
    "        one_hot[0][target_category] = 1\n",
    "        one_hot = torch.from_numpy(one_hot).requires_grad_(True)\n",
    "        if self.cuda:\n",
    "            one_hot = one_hot.cuda()\n",
    "        \n",
    "        one_hot = torch.sum(one_hot * output)\n",
    "\n",
    "        self.feature_module.zero_grad()\n",
    "        self.model.zero_grad()\n",
    "        one_hot.backward(retain_graph=True)\n",
    "\n",
    "        grads_val = self.extractor.get_gradients()[-1].cpu().data.numpy()\n",
    "\n",
    "        target = features[-1]\n",
    "        target = target.cpu().data.numpy()[0, :]\n",
    "\n",
    "        weights = np.mean(grads_val, axis=(2, 3))[0, :]\n",
    "        cam = np.zeros(target.shape[1:], dtype=np.float32)\n",
    "\n",
    "        for i, w in enumerate(weights):\n",
    "            cam += w * target[i, :, :]\n",
    "\n",
    "        cam = np.maximum(cam, 0)\n",
    "        cam = cv2.resize(cam, input_img.shape[2:])\n",
    "        cam = cam - np.min(cam)\n",
    "        cam = cam / np.max(cam)\n",
    "        return cam\n",
    "\n",
    "\n",
    "class GuidedBackpropReLU(Function):\n",
    "    @staticmethod\n",
    "    def forward(self, input_img):\n",
    "        positive_mask = (input_img > 0).type_as(input_img)\n",
    "        output = torch.addcmul(torch.zeros(input_img.size()).type_as(input_img), input_img, positive_mask)\n",
    "        self.save_for_backward(input_img, output)\n",
    "        return output\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(self, grad_output):\n",
    "        input_img, output = self.saved_tensors\n",
    "        grad_input = None\n",
    "\n",
    "        positive_mask_1 = (input_img > 0).type_as(grad_output)\n",
    "        positive_mask_2 = (grad_output > 0).type_as(grad_output)\n",
    "        grad_input = torch.addcmul(torch.zeros(input_img.size()).type_as(input_img),\n",
    "                                   torch.addcmul(torch.zeros(input_img.size()).type_as(input_img), grad_output,\n",
    "                                                 positive_mask_1), positive_mask_2)\n",
    "        return grad_input\n",
    "\n",
    "\n",
    "class GuidedBackpropReLUModel:\n",
    "    def __init__(self, model, use_cuda):\n",
    "        self.model = model\n",
    "        self.model.eval()\n",
    "        self.cuda = use_cuda\n",
    "        if self.cuda:\n",
    "            self.model = model.cuda()\n",
    "\n",
    "        def recursive_relu_apply(module_top):\n",
    "            for idx, module in module_top._modules.items():\n",
    "                recursive_relu_apply(module)\n",
    "                if module.__class__.__name__ == 'ReLU':\n",
    "                    module_top._modules[idx] = GuidedBackpropReLU.apply\n",
    "\n",
    "        # replace ReLU with GuidedBackpropReLU\n",
    "        recursive_relu_apply(self.model)\n",
    "\n",
    "    def forward(self, input_img):\n",
    "        return self.model(input_img)\n",
    "\n",
    "    def __call__(self, input_img, target_category=None):\n",
    "        if self.cuda:\n",
    "            input_img = input_img.cuda()\n",
    "\n",
    "        input_img = input_img.requires_grad_(True)\n",
    "\n",
    "        output = self.forward(input_img)\n",
    "\n",
    "        if target_category == None:\n",
    "            target_category = np.argmax(output.cpu().data.numpy())\n",
    "\n",
    "        one_hot = np.zeros((1, output.size()[-1]), dtype=np.float32)\n",
    "        one_hot[0][target_category] = 1\n",
    "        one_hot = torch.from_numpy(one_hot).requires_grad_(True)\n",
    "        if self.cuda:\n",
    "            one_hot = one_hot.cuda()\n",
    "\n",
    "        one_hot = torch.sum(one_hot * output)\n",
    "        one_hot.backward(retain_graph=True)\n",
    "\n",
    "        output = input_img.grad.cpu().data.numpy()\n",
    "        output = output[0, :, :, :]\n",
    "\n",
    "        return output\n",
    "\n",
    "def get_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--use-cuda', action='store_true', default=False,\n",
    "                        help='Use NVIDIA GPU acceleration')\n",
    "    parser.add_argument('--image-path', type=str, default='./examples/both.png',\n",
    "                        help='Input image path')\n",
    "    args = parser.parse_args()\n",
    "    args.use_cuda = args.use_cuda and torch.cuda.is_available()\n",
    "    if args.use_cuda:\n",
    "        print(\"Using GPU for acceleration\")\n",
    "    else:\n",
    "        print(\"Using CPU for computation\")\n",
    "\n",
    "    return args\n",
    "\n",
    "def deprocess_image(img):\n",
    "    \"\"\" see https://github.com/jacobgil/keras-grad-cam/blob/master/grad-cam.py#L65 \"\"\"\n",
    "    img = img - np.mean(img)\n",
    "    img = img / (np.std(img) + 1e-5)\n",
    "    img = img * 0.1\n",
    "    img = img + 0.5\n",
    "    img = np.clip(img, 0, 1)\n",
    "    return np.uint8(img*255)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \"\"\" python grad_cam.py <path_to_image>\n",
    "    1. Loads an image with opencv.\n",
    "    2. Preprocesses it for ResNet50 and converts to a pytorch variable.\n",
    "    3. Makes a forward pass to find the category index with the highest score,\n",
    "    and computes intermediate activations.\n",
    "    Makes the visualization. \"\"\"\n",
    "\n",
    "    #Load saved best model\n",
    "    model = CustomModel()\n",
    "    ckpt = torch.load('fullmodel_trial.ckpt')\n",
    "    model.load_state_dict(ckpt[\"model\"])\n",
    "    \n",
    "    #specifying layer to visualize activations\n",
    "    grad_cam = GradCam(model=model, feature_module=model.encoder.f, \\\n",
    "                       target_layer_names=[\"7\"], use_cuda=True)\n",
    "\n",
    "    img = cv2.imread('train/cgm/train-cgm-651.jpg', 1)\n",
    "    img = np.float32(img) / 255\n",
    "    # Opencv loads as BGR:\n",
    "    img = img[:, :, ::-1]\n",
    "    input_img = preprocess_image(img)\n",
    "\n",
    "    # If None, returns the map for the highest scoring category.\n",
    "    # Otherwise, targets the requested category.\n",
    "    target_category = None\n",
    "    grayscale_cam = grad_cam(input_img, target_category)\n",
    "\n",
    "    grayscale_cam = cv2.resize(grayscale_cam, (img.shape[1], img.shape[0]))\n",
    "    cam = show_cam_on_image(img, grayscale_cam)\n",
    "\n",
    "    gb_model = GuidedBackpropReLUModel(model=model, use_cuda=True)\n",
    "    gb = gb_model(input_img, target_category=target_category)\n",
    "    gb = gb.transpose((1, 2, 0))\n",
    "\n",
    "    cam_mask = cv2.merge([grayscale_cam, grayscale_cam, grayscale_cam])\n",
    "    cam_gb = deprocess_image(cam_mask*gb)\n",
    "    gb = deprocess_image(gb)\n",
    "\n",
    "    cv2.imwrite(\"cgm.jpg\", cam)\n",
    "    cv2.imwrite('gb.jpg', gb)\n",
    "    cv2.imwrite('cam_gb.jpg', cam_gb)\n",
    "    print('done')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
