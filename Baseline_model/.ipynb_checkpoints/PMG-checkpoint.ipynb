{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.autograd import Variable\n",
    "from torchvision import transforms, models\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining Resnet models\n",
    "Credit: https://github.com/PRIS-CV/PMG-Progressive-Multi-Granularity-Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from  torch.utils.model_zoo import load_url as load_state_dict_from_url\n",
    "\n",
    "#Defining resnet models\n",
    "\n",
    "__all__ = ['ResNet', 'resnet18', 'resnet34', 'resnet50', 'resnet101',\n",
    "           'resnet152', 'resnext50_32x4d', 'resnext101_32x8d']\n",
    "\n",
    "\n",
    "model_urls = {\n",
    "    'resnet18': 'https://download.pytorch.org/models/resnet18-5c106cde.pth',\n",
    "    'resnet34': 'https://download.pytorch.org/models/resnet34-333f7ec4.pth',\n",
    "    'resnet50': 'https://download.pytorch.org/models/resnet50-19c8e357.pth',\n",
    "    'resnet101': 'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth',\n",
    "    'resnet152': 'https://download.pytorch.org/models/resnet152-b121ed2d.pth',\n",
    "}\n",
    "\n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1, groups=1, dilation=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=dilation, groups=groups, bias=False, dilation=dilation)\n",
    "\n",
    "\n",
    "def conv1x1(in_planes, out_planes, stride=1):\n",
    "    \"\"\"1x1 convolution\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n",
    "                 base_width=64, dilation=1, norm_layer=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        if groups != 1 or base_width != 64:\n",
    "            raise ValueError('BasicBlock only supports groups=1 and base_width=64')\n",
    "        if dilation > 1:\n",
    "            raise NotImplementedError(\"Dilation > 1 not supported in BasicBlock\")\n",
    "        # Both self.conv1 and self.downsample layers downsample the input when stride != 1\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = norm_layer(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = norm_layer(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n",
    "                 base_width=64, dilation=1, norm_layer=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        width = int(planes * (base_width / 64.)) * groups\n",
    "        # Both self.conv2 and self.downsample layers downsample the input when stride != 1\n",
    "        self.conv1 = conv1x1(inplanes, width)\n",
    "        self.bn1 = norm_layer(width)\n",
    "        self.conv2 = conv3x3(width, width, stride, groups, dilation)\n",
    "        self.bn2 = norm_layer(width)\n",
    "        self.conv3 = conv1x1(width, planes * self.expansion)\n",
    "        self.bn3 = norm_layer(planes * self.expansion)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, num_classes=1000, zero_init_residual=False,\n",
    "                 groups=1, width_per_group=64, replace_stride_with_dilation=None,\n",
    "                 norm_layer=None):\n",
    "        super(ResNet, self).__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        self._norm_layer = norm_layer\n",
    "\n",
    "        self.inplanes = 64\n",
    "        self.dilation = 1\n",
    "        if replace_stride_with_dilation is None:\n",
    "            # each element in the tuple indicates if we should replace\n",
    "            # the 2x2 stride with a dilated convolution instead\n",
    "            replace_stride_with_dilation = [False, False, False]\n",
    "        if len(replace_stride_with_dilation) != 3:\n",
    "            raise ValueError(\"replace_stride_with_dilation should be None \"\n",
    "                             \"or a 3-element tuple, got {}\".format(replace_stride_with_dilation))\n",
    "        self.groups = groups\n",
    "        self.base_width = width_per_group\n",
    "        self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "        self.bn1 = norm_layer(self.inplanes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[0])\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[1])\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[2])\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "        # Zero-initialize the last BN in each residual branch,\n",
    "        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n",
    "        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n",
    "        if zero_init_residual:\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, Bottleneck):\n",
    "                    nn.init.constant_(m.bn3.weight, 0)\n",
    "                elif isinstance(m, BasicBlock):\n",
    "                    nn.init.constant_(m.bn2.weight, 0)\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1, dilate=False):\n",
    "        norm_layer = self._norm_layer\n",
    "        downsample = None\n",
    "        previous_dilation = self.dilation\n",
    "        if dilate:\n",
    "            self.dilation *= stride\n",
    "            stride = 1\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                conv1x1(self.inplanes, planes * block.expansion, stride),\n",
    "                norm_layer(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample, self.groups,\n",
    "                            self.base_width, previous_dilation, norm_layer))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes, groups=self.groups,\n",
    "                                base_width=self.base_width, dilation=self.dilation,\n",
    "                                norm_layer=norm_layer))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x1 = self.maxpool(x)\n",
    "\n",
    "        x2 = self.layer1(x1)\n",
    "        x3 = self.layer2(x2)\n",
    "        x4 = self.layer3(x3)\n",
    "        x5 = self.layer4(x4)\n",
    "\n",
    "        x = self.avgpool(x5)\n",
    "        x = x.reshape(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x1, x2, x3, x4, x5\n",
    "\n",
    "\n",
    "def _resnet(arch, inplanes, planes, pretrained, progress, **kwargs):\n",
    "    model = ResNet(inplanes, planes, **kwargs)\n",
    "    if pretrained:\n",
    "        state_dict = load_state_dict_from_url(model_urls[arch],\n",
    "                                              progress=progress)\n",
    "        model.load_state_dict(state_dict)\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet18(pretrained=False, progress=True, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-18 model.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "    \"\"\"\n",
    "    return _resnet('resnet18', BasicBlock, [2, 2, 2, 2], pretrained, progress,\n",
    "                   **kwargs)\n",
    "\n",
    "\n",
    "def resnet34(pretrained=False, progress=True, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-34 model.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "    \"\"\"\n",
    "    return _resnet('resnet34', BasicBlock, [3, 4, 6, 3], pretrained, progress,\n",
    "                   **kwargs)\n",
    "\n",
    "\n",
    "def resnet50(pretrained=False, progress=True, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-50 model.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "    \"\"\"\n",
    "    return _resnet('resnet50', Bottleneck, [3, 4, 6, 3], pretrained, progress,\n",
    "                   **kwargs)\n",
    "\n",
    "\n",
    "def resnet101(pretrained=False, progress=True, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-101 model.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "    \"\"\"\n",
    "    return _resnet('resnet101', Bottleneck, [3, 4, 23, 3], pretrained, progress,\n",
    "                   **kwargs)\n",
    "\n",
    "\n",
    "def resnet152(pretrained=False, progress=True, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-152 model.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "    \"\"\"\n",
    "    return _resnet('resnet152', Bottleneck, [3, 8, 36, 3], pretrained, progress,\n",
    "                   **kwargs)\n",
    "\n",
    "\n",
    "def resnext50_32x4d(**kwargs):\n",
    "    kwargs['groups'] = 32\n",
    "    kwargs['width_per_group'] = 4\n",
    "    return _resnet('resnext50_32x4d', Bottleneck, [3, 4, 6, 3],\n",
    "                   pretrained=False, progress=True, **kwargs)\n",
    "\n",
    "\n",
    "def resnext101_32x8d(**kwargs):\n",
    "    kwargs['groups'] = 32\n",
    "    kwargs['width_per_group'] = 8\n",
    "    return _resnet('resnext101_32x8d', Bottleneck, [3, 4, 23, 3],\n",
    "                   pretrained=False, progress=True, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PMG model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "    \n",
    "#Multi granularity network - PMG\n",
    "class PMG(nn.Module):\n",
    "    def __init__(self, model, feature_size, classes_num):\n",
    "        super(PMG, self).__init__()\n",
    "\n",
    "        self.features = model\n",
    "        self.max1 = nn.MaxPool2d(kernel_size=56, stride=56)\n",
    "        self.max2 = nn.MaxPool2d(kernel_size=28, stride=28)\n",
    "        self.max3 = nn.MaxPool2d(kernel_size=14, stride=14)\n",
    "        self.num_ftrs = 2048 * 1 * 1\n",
    "        self.elu = nn.ELU(inplace=True)\n",
    "\n",
    "        self.classifier_concat = nn.Sequential(\n",
    "            nn.BatchNorm1d(1024 * 3),\n",
    "            nn.Linear(1024 * 3, feature_size),\n",
    "            nn.BatchNorm1d(feature_size),\n",
    "            nn.ELU(inplace=True),\n",
    "            nn.Linear(feature_size, classes_num),\n",
    "        )\n",
    "\n",
    "        self.conv_block1 = nn.Sequential(\n",
    "            BasicConv(self.num_ftrs//4, feature_size, kernel_size=1, stride=1, padding=0, relu=True),\n",
    "            BasicConv(feature_size, self.num_ftrs//2, kernel_size=3, stride=1, padding=1, relu=True)\n",
    "        )\n",
    "        self.classifier1 = nn.Sequential(\n",
    "            nn.BatchNorm1d(self.num_ftrs//2),\n",
    "            nn.Linear(self.num_ftrs//2, feature_size),\n",
    "            nn.BatchNorm1d(feature_size),\n",
    "            nn.ELU(inplace=True),\n",
    "            nn.Linear(feature_size, classes_num),\n",
    "        )\n",
    "\n",
    "        self.conv_block2 = nn.Sequential(\n",
    "            BasicConv(self.num_ftrs//2, feature_size, kernel_size=1, stride=1, padding=0, relu=True),\n",
    "            BasicConv(feature_size, self.num_ftrs//2, kernel_size=3, stride=1, padding=1, relu=True)\n",
    "        )\n",
    "        self.classifier2 = nn.Sequential(\n",
    "            nn.BatchNorm1d(self.num_ftrs//2),\n",
    "            nn.Linear(self.num_ftrs//2, feature_size),\n",
    "            nn.BatchNorm1d(feature_size),\n",
    "            nn.ELU(inplace=True),\n",
    "            nn.Linear(feature_size, classes_num),\n",
    "        )\n",
    "\n",
    "        self.conv_block3 = nn.Sequential(\n",
    "            BasicConv(self.num_ftrs, feature_size, kernel_size=1, stride=1, padding=0, relu=True),\n",
    "            BasicConv(feature_size, self.num_ftrs//2, kernel_size=3, stride=1, padding=1, relu=True)\n",
    "        )\n",
    "        self.classifier3 = nn.Sequential(\n",
    "            nn.BatchNorm1d(self.num_ftrs//2),\n",
    "            nn.Linear(self.num_ftrs//2, feature_size),\n",
    "            nn.BatchNorm1d(feature_size),\n",
    "            nn.ELU(inplace=True),\n",
    "            nn.Linear(feature_size, classes_num),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        xf1, xf2, xf3, xf4, xf5 = self.features(x)\n",
    "\n",
    "        xl1 = self.conv_block1(xf3)\n",
    "        xl2 = self.conv_block2(xf4)\n",
    "        xl3 = self.conv_block3(xf5)\n",
    "        \n",
    "        xl1 = self.max1(xl1)\n",
    "        xl1 = xl1.view(xl1.size(0), -1)\n",
    "        xc1 = self.classifier1(xl1)\n",
    "\n",
    "        xl2 = self.max2(xl2)\n",
    "        xl2 = xl2.view(xl2.size(0), -1)\n",
    "        xc2 = self.classifier2(xl2)\n",
    "\n",
    "        xl3 = self.max3(xl3)\n",
    "        xl3 = xl3.view(xl3.size(0), -1)\n",
    "        xc3 = self.classifier3(xl3)\n",
    "          \n",
    "        x_concat = torch.cat((xl1, xl2, xl3), -1)\n",
    "        x_concat = self.classifier_concat(x_concat)\n",
    "        return xc1, xc2, xc3, x_concat\n",
    "    \n",
    "    \n",
    "class BasicConv(nn.Module):\n",
    "    def __init__(self, in_planes, out_planes, kernel_size, stride=1, padding=0, dilation=1, groups=1, relu=True, bn=True, bias=False):\n",
    "        super(BasicConv, self).__init__()\n",
    "        self.out_channels = out_planes\n",
    "        self.conv = nn.Conv2d(in_planes, out_planes, kernel_size=kernel_size,\n",
    "                              stride=stride, padding=padding, dilation=dilation, groups=groups, bias=bias)\n",
    "        self.bn = nn.BatchNorm2d(out_planes, eps=1e-5,\n",
    "                                 momentum=0.01, affine=True) if bn else None\n",
    "        self.relu = nn.ReLU() if relu else None\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        if self.bn is not None:\n",
    "            x = self.bn(x)\n",
    "        if self.relu is not None:\n",
    "            x = self.relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.autograd import Variable\n",
    "from torchvision import transforms, models\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#learning rate scheduler\n",
    "def cosine_anneal_schedule(t, nb_epoch, lr):\n",
    "    cos_inner = np.pi * (t % (nb_epoch))  # t - 1 is used when t has 1-based indexing.\n",
    "    cos_inner /= (nb_epoch)\n",
    "    cos_out = np.cos(cos_inner) + 1\n",
    "\n",
    "    return float(lr / 2 * cos_out)\n",
    "\n",
    "\n",
    "def load_model(model_name, pretrain=True, require_grad=True):\n",
    "    print('==> Building model..')\n",
    "    if model_name == 'resnet50_pmg':\n",
    "        net = resnet50(pretrained=pretrain)\n",
    "        print(\"loaded\")\n",
    "        for param in net.parameters():\n",
    "            param.requires_grad = require_grad\n",
    "        num_ftrs = net.fc.in_features\n",
    "        net.fc = nn.Linear(num_ftrs, 5)\n",
    "        net = PMG(net, 512, 200)\n",
    "\n",
    "    return net\n",
    "\n",
    "#Prints model summary\n",
    "def model_info(model):  # Plots a line-by-line description of a PyTorch model\n",
    "    n_p = sum(x.numel() for x in model.parameters())  # number parameters\n",
    "    n_g = sum(x.numel() for x in model.parameters() if x.requires_grad)  # number gradients\n",
    "    print('\\n%5s %50s %9s %12s %20s %12s %12s' % ('layer', 'name', 'gradient', 'parameters', 'shape', 'mu', 'sigma'))\n",
    "    for i, (name, p) in enumerate(model.named_parameters()):\n",
    "        name = name.replace('module_list.', '')\n",
    "        print('%5g %50s %9s %12g %20s %12.3g %12.3g' % (\n",
    "            i, name, p.requires_grad, p.numel(), list(p.shape), p.mean(), p.std()))\n",
    "    print('Model Summary: %g layers, %g parameters, %g gradients\\n' % (i + 1, n_p, n_g))\n",
    "\n",
    "#Performs jigsaw\n",
    "def jigsaw_generator(images, n):\n",
    "    l = []\n",
    "    for a in range(n):\n",
    "        for b in range(n):\n",
    "            l.append([a, b])\n",
    "    block_size = 448 // n\n",
    "    rounds = n ** 2\n",
    "    random.shuffle(l)\n",
    "    jigsaws = images.clone()\n",
    "    for i in range(rounds):\n",
    "        x, y = l[i]\n",
    "        temp = jigsaws[..., 0:block_size, 0:block_size].clone()\n",
    "        jigsaws[..., 0:block_size, 0:block_size] = jigsaws[..., x * block_size:(x + 1) * block_size,\n",
    "                                                y * block_size:(y + 1) * block_size].clone()\n",
    "        jigsaws[..., x * block_size:(x + 1) * block_size, y * block_size:(y + 1) * block_size] = temp\n",
    "\n",
    "    return jigsaws\n",
    "\n",
    "\n",
    "#function for validation\n",
    "def test(net, criterion, batch_size,testloader):\n",
    "    net.eval()\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    correct_com = 0\n",
    "    total = 0\n",
    "    idx = 0\n",
    "    device = torch.device(\"cuda:0\")\n",
    "\n",
    "    transform_test = transforms.Compose([\n",
    "        transforms.Scale((550, 550)),\n",
    "        transforms.CenterCrop(448),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "    ])\n",
    "    testset = torchvision.datasets.ImageFolder(root='val/',\n",
    "                                               transform=transform_test)\n",
    "    testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "\n",
    "    for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "        idx = batch_idx\n",
    "        if use_cuda:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "        inputs, targets = Variable(inputs, volatile=True), Variable(targets)\n",
    "        output_1, output_2, output_3, output_concat= net(inputs)\n",
    "        outputs_com = output_1 + output_2 + output_3 + output_concat\n",
    "\n",
    "        loss = criterion(output_concat, targets)\n",
    "\n",
    "        test_loss += loss.item()\n",
    "        _, predicted = torch.max(output_concat.data, 1)\n",
    "        _, predicted_com = torch.max(outputs_com.data, 1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets.data).cpu().sum()\n",
    "        correct_com += predicted_com.eq(targets.data).cpu().sum()\n",
    "\n",
    "        if batch_idx % 50 == 0:\n",
    "            print('Step: %d | Loss: %.3f | Acc: %.3f%% (%d/%d) |Combined Acc: %.3f%% (%d/%d)' % (\n",
    "            batch_idx, test_loss / (batch_idx + 1), 100. * float(correct) / total, correct, total, 100. * float(correct_com) / total, correct_com, total))\n",
    "\n",
    "    test_acc = 100. * float(correct) / total\n",
    "    test_acc_en = 100. * float(correct_com) / total\n",
    "    test_loss = test_loss / (idx + 1)\n",
    "\n",
    "    return test_acc, test_acc_en, test_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prints confusion matrix\n",
    "def conf_matrix(net, criterion, batch_size,testloader):\n",
    "\n",
    "    net.eval()\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    correct_com = 0\n",
    "    total = 0\n",
    "    idx = 0\n",
    "    device = torch.device(\"cuda:0\")\n",
    "\n",
    "    transform_test = transforms.Compose([\n",
    "        transforms.Scale((550, 550)),\n",
    "        transforms.CenterCrop(448),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "    ])\n",
    "    confusion_matrix = torch.zeros(5,5)\n",
    "    \n",
    "    #on validation set\n",
    "    for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "        idx = batch_idx\n",
    "        if use_cuda:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "        inputs, targets = Variable(inputs, volatile=True), Variable(targets)\n",
    "        output_1, output_2, output_3, output_concat= net(inputs)\n",
    "        outputs_com = output_1 + output_2 + output_3 + output_concat\n",
    "\n",
    "        loss = criterion(output_concat, targets)\n",
    "\n",
    "        test_loss += loss.item()\n",
    "        _, predicted = torch.max(output_concat.data, 1)\n",
    "        _, predicted_com = torch.max(outputs_com.data, 1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets.data).cpu().sum()\n",
    "        correct_com += predicted_com.eq(targets.data).cpu().sum()\n",
    "        \n",
    "        for l, p in zip(targets.view(-1), predicted_com.view(-1)):\n",
    "            confusion_matrix[l.long(), p.long()] += 1\n",
    "\n",
    "        if batch_idx % 50 == 0:\n",
    "            print('Step: %d | Loss: %.3f | Acc: %.3f%% (%d/%d) |Combined Acc: %.3f%% (%d/%d)' % (\n",
    "            batch_idx, test_loss / (batch_idx + 1), 100. * float(correct) / total, correct, total, 100. * float(correct_com) / total, correct_com, total))\n",
    "    \n",
    "    print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PMG model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "import logging\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torchvision import transforms, models\n",
    "import random\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Train model\n",
    "def train(nb_epoch, batch_size, store_name, resume=False, start_epoch=0, model_path=None):\n",
    "    # setup output\n",
    "    exp_dir = store_name\n",
    "    try:\n",
    "        os.stat(exp_dir)\n",
    "    except:\n",
    "        os.makedirs(exp_dir)\n",
    "\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    print(use_cuda)\n",
    "\n",
    "    # Data\n",
    "    print('==> Preparing data..')\n",
    "    transform_train = transforms.Compose([\n",
    "        transforms.Scale((550, 550)),\n",
    "        transforms.RandomCrop(448, padding=8),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "    ])\n",
    "    train_dataset = datasets.ImageFolder(root='train_combined',transform=transform_train)\n",
    "    \n",
    "    num_train = len(train_dataset)\n",
    "    indices = list(range(num_train))\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "    split = int(np.floor(0.2 * num_train))\n",
    "    train_idx, valid_idx = indices[split:], indices[:split]\n",
    "\n",
    "    # define samplers for obtaining training and validation batches\n",
    "    train_sampler = SubsetRandomSampler(train_idx)\n",
    "        \n",
    "    valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "\n",
    "    trainloader = DataLoader(train_dataset, batch_size=16,sampler=train_sampler,num_workers=8, drop_last=True, shuffle=False)\n",
    "\n",
    "    test_loader = DataLoader(train_dataset, batch_size=16,sampler=valid_sampler,num_workers=8, drop_last=True)\n",
    "    \n",
    "    # Model\n",
    "    if resume:\n",
    "        net = torch.load(model_path)\n",
    "    else:\n",
    "        net = load_model(model_name='resnet50_pmg', pretrain=True, require_grad=True)\n",
    "    netp = torch.nn.DataParallel(net, device_ids=[0])\n",
    "\n",
    "    # GPU\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    net.to(device)\n",
    "    # cudnn.benchmark = True\n",
    "\n",
    "    CELoss = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD([\n",
    "        {'params': net.classifier_concat.parameters(), 'lr': 0.002},\n",
    "        {'params': net.conv_block1.parameters(), 'lr': 0.002},\n",
    "        {'params': net.classifier1.parameters(), 'lr': 0.002},\n",
    "        {'params': net.conv_block2.parameters(), 'lr': 0.002},\n",
    "        {'params': net.classifier2.parameters(), 'lr': 0.002},\n",
    "        {'params': net.conv_block3.parameters(), 'lr': 0.002},\n",
    "        {'params': net.classifier3.parameters(), 'lr': 0.002},\n",
    "        {'params': net.features.parameters(), 'lr': 0.0002}\n",
    "\n",
    "    ],\n",
    "        momentum=0.9, weight_decay=5e-4)\n",
    "\n",
    "    max_val_acc = 0\n",
    "    tloss = []\n",
    "    vloss = []\n",
    "    lr = [0.002, 0.002, 0.002, 0.002, 0.002, 0.002, 0.002, 0.0002]\n",
    "    for epoch in range(start_epoch, nb_epoch):\n",
    "        print('\\nEpoch: %d' % epoch)\n",
    "        net.train()\n",
    "        train_loss = 0\n",
    "        train_loss1 = 0\n",
    "        train_loss2 = 0\n",
    "        train_loss3 = 0\n",
    "        train_loss4 = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        idx = 0\n",
    "        for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "            idx = batch_idx\n",
    "            if inputs.shape[0] < batch_size:\n",
    "                continue\n",
    "            if use_cuda:\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "            inputs, targets = Variable(inputs), Variable(targets)\n",
    "\n",
    "            # update learning rate\n",
    "            for nlr in range(len(optimizer.param_groups)):\n",
    "                optimizer.param_groups[nlr]['lr'] = cosine_anneal_schedule(epoch, nb_epoch, lr[nlr])\n",
    "\n",
    "            # Step 1 - granularity 8\n",
    "            optimizer.zero_grad()\n",
    "            inputs1 = jigsaw_generator(inputs, 8)\n",
    "            output_1, _, _, _ = netp(inputs1)\n",
    "            loss1 = CELoss(output_1, targets) * 1\n",
    "            loss1.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Step 2 - granularity 4\n",
    "            optimizer.zero_grad()\n",
    "            inputs2 = jigsaw_generator(inputs, 4)\n",
    "            _, output_2, _, _ = netp(inputs2)\n",
    "            loss2 = CELoss(output_2, targets) * 1\n",
    "            loss2.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Step 3 - - granularity 2\n",
    "            optimizer.zero_grad()\n",
    "            inputs3 = jigsaw_generator(inputs, 2)\n",
    "            _, _, output_3, _ = netp(inputs3)\n",
    "            loss3 = CELoss(output_3, targets) * 1\n",
    "            loss3.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Step 4 - input image\n",
    "            optimizer.zero_grad()\n",
    "            _, _, _, output_concat = netp(inputs)\n",
    "            concat_loss = CELoss(output_concat, targets) * 2\n",
    "            concat_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            #  training log\n",
    "            _, predicted = torch.max(output_concat.data, 1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets.data).cpu().sum()\n",
    "\n",
    "            train_loss += (loss1.item() + loss2.item() + loss3.item() + concat_loss.item())\n",
    "            train_loss1 += loss1.item()\n",
    "            train_loss2 += loss2.item()\n",
    "            train_loss3 += loss3.item()\n",
    "            train_loss4 += concat_loss.item()\n",
    "\n",
    "            if batch_idx % 50 == 0:\n",
    "                print(\n",
    "                    'Step: %d | Loss1: %.3f | Loss2: %.5f | Loss3: %.5f | Loss_concat: %.5f | Loss: %.3f | Acc: %.3f%% (%d/%d)' % (\n",
    "                    batch_idx, train_loss1 / (batch_idx + 1), train_loss2 / (batch_idx + 1),\n",
    "                    train_loss3 / (batch_idx + 1), train_loss4 / (batch_idx + 1), train_loss / (batch_idx + 1),\n",
    "                    100. * float(correct) / total, correct, total))\n",
    "        \n",
    "        train_acc = 100. * float(correct) / total\n",
    "        train_loss = train_loss / (idx + 1)\n",
    "        tloss.append(train_loss)\n",
    "        with open(exp_dir + '/results_train.txt', 'a') as file:\n",
    "            file.write(\n",
    "                'Iteration %d | train_acc = %.5f | train_loss = %.5f | Loss1: %.3f | Loss2: %.5f | Loss3: %.5f | Loss_concat: %.5f |\\n' % (\n",
    "                epoch, train_acc, train_loss, train_loss1 / (idx + 1), train_loss2 / (idx + 1), train_loss3 / (idx + 1),\n",
    "                train_loss4 / (idx + 1)))\n",
    "\n",
    "       \n",
    "        #validation epoch\n",
    "        val_acc, val_acc_com, val_loss = test(net, CELoss, 3,test_loader)\n",
    "        vloss.append(val_loss)\n",
    "        if val_acc_com > max_val_acc:\n",
    "            max_val_acc = val_acc_com            \n",
    "            torch.save(net, './' + store_name + '/model.pth')\n",
    "        with open(exp_dir + '/results_test.txt', 'a') as file:\n",
    "            file.write('Iteration %d, test_acc = %.5f, test_acc_combined = %.5f, test_loss = %.6f\\n' % (\n",
    "            epoch, val_acc, val_acc_com, val_loss))\n",
    "            \n",
    "        net.cpu()\n",
    "        net.to(device)\n",
    "    \n",
    "    eps = range(1, len(tloss) + 1)\n",
    "    plt.plot(eps, tloss, 'b', label='Training loss')\n",
    "    plt.plot(eps, vloss, 'r', label='Validation loss')\n",
    "    plt.title('Training and Validation loss')\n",
    "    plt.legend()\n",
    "    plt.savefig('loss_plot.png')\n",
    "    #prints confusion matrix\n",
    "    conf_matrix(net,CELoss, 3,test_loader)\n",
    "\n",
    "train(nb_epoch=100,             # number of epoch\n",
    "         batch_size=16,         # batch size\n",
    "         store_name='leaf',     # folder for output\n",
    "         resume=False,          # resume training from checkpoint\n",
    "         start_epoch=0,         # the start epoch number when you resume the training\n",
    "         model_path='')         # the saved model where you want to resume the training"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
