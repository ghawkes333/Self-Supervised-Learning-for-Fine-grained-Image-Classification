{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pretrained weights from SRGAN for the cassava dataset were initially obtained following the instructions available here: https://github.com/Lornatang/SRGAN-PyTorch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# List of dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch-summary\n",
    "!pip install grad-cam\n",
    "\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from torch.autograd import Variable\n",
    "from torchsummary import summary\n",
    "\n",
    "# dataset\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "\n",
    "# data augmentations\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import ConcatDataset\n",
    "\n",
    "# model discriminator\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# quantitative eval\n",
    "from PIL import Image\n",
    "from collections import Counter\n",
    "\n",
    "# qualitative eval\n",
    "from pytorch_grad_cam import GradCAM, ScoreCAM, GradCAMPlusPlus, AblationCAM, XGradCAM\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "\n",
    "import argparse\n",
    "import cv2\n",
    "import numpy as np\n",
    "from torch.autograd import Function\n",
    "from torchvision import models\n",
    "\n",
    "# experiments\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part A. Function Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Dataset\n",
    "Data loading and data split.\n",
    "\n",
    "Source:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetDataset(Dataset):\n",
    "    'Characterizes a dataset for PyTorch'\n",
    "    def __init__(self, file_paths, labels, transform=None):\n",
    "        'Initialization'\n",
    "        self.imgs = [(img_path, label) for img_path, label in zip(file_paths, labels)]\n",
    "        self.file_paths = file_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        return len(self.file_paths)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generates one sample of data'\n",
    "\n",
    "        # Select sample\n",
    "        file_path = self.file_paths[index]\n",
    "        label = self.labels[index]\n",
    "        pil_image = Image.open(file_path)\n",
    "\n",
    "        # Check if image has only single channel. If True, then swap with 0th image\n",
    "        # Assumption 0th image has got 3 number of channels\n",
    "        if len(pil_image.getbands()) != 3:\n",
    "            file_path = self.file_paths[0]\n",
    "            label = self.labels[0]\n",
    "            pil_image = Image.open(file_path)\n",
    "\n",
    "        # Convert image to torch tensor\n",
    "        if self.transform != None:\n",
    "            tr_image = self.transform(pil_image)\n",
    "        else:\n",
    "            tr_image = transforms.ToTensor()(pil_image).unsqueeze_(0)\n",
    "\n",
    "        return tr_image, label\n",
    "    \n",
    "\n",
    "def split_train_into_train_val(train_file_ids, train_file_paths, train_labels, test_size=0.1):\n",
    "    \"\"\"\n",
    "    Split train_file_paths and train_labels to train_file_paths, val_file_paths and\n",
    "    train_labels, val_labels\n",
    "    \"\"\"\n",
    "\n",
    "    # Create a mapping between image_id and file_path\n",
    "    image_id_name_map = dict(zip(train_file_ids, train_file_paths))\n",
    "\n",
    "    # Get validation files and validation labels separate\n",
    "    train_file_ids, val_file_ids, train_labels, val_labels = train_test_split(\n",
    "        train_file_ids, train_labels, test_size=test_size, random_state=5, shuffle=True\n",
    "    )\n",
    "    train_file_paths = [image_id_name_map[image_id] for image_id in train_file_ids]\n",
    "    val_file_paths = [image_id_name_map[image_id] for image_id in val_file_ids]\n",
    "\n",
    "    print (\"Length of train files list\", len(train_file_paths))\n",
    "    print (\"Length of train labels\", len(train_labels))\n",
    "    print (\"Length of val files list\", len(val_file_paths))\n",
    "    print (\"Length of val labels\", len(val_labels))\n",
    "\n",
    "    return train_file_ids, val_file_ids, train_file_paths, val_file_paths, train_labels, val_labels\n",
    "\n",
    "\n",
    "def get_train_test_file_paths_n_labels():\n",
    "    \"\"\"\n",
    "    Get array train_file_paths, train_labels, test_file_paths and test_labels\n",
    "    \"\"\"\n",
    "\n",
    "    # Data loading and data discriminators set up\n",
    "    images_data_dir = r'../input/SRGANPyTorch_Lornatang/data/TRAIN'\n",
    "    train_test_split_file = r'../input/SRGANPyTorch_Lornatang/from-rg/train_test_split.txt'\n",
    "    images_file = r'../input/SRGANPyTorch_Lornatang/from-rg/images.txt'\n",
    "    labels_file = r'../input/SRGANPyTorch_Lornatang/from-rg/image_class_labels.txt'\n",
    "\n",
    "    # Read the images_file which stores image-id and image-name mapping\n",
    "    image_file_id_df = pd.read_csv(images_file, sep=' ', header=None)\n",
    "    image_file_id_mat = image_file_id_df.values\n",
    "    image_id_name_map = dict(zip(image_file_id_mat[:, 0], image_file_id_mat[:, 1]))\n",
    "\n",
    "    # Read the train_test_split file which stores image-id and train-test split mapping\n",
    "    image_id_train_test_split_df = pd.read_csv(train_test_split_file, sep=' ', header=None)\n",
    "    image_id_train_test_split_mat = image_id_train_test_split_df.values\n",
    "    image_id_train_test_split_map = dict(zip(image_id_train_test_split_mat[:, 0],\n",
    "                                             image_id_train_test_split_mat[:, 1]))\n",
    "\n",
    "    # Read the image class labels file\n",
    "    image_id_label_df = pd.read_csv(labels_file, sep=' ', header=None)\n",
    "    image_id_label_mat = image_id_label_df.values\n",
    "    image_id_label_map = dict(zip(image_id_label_mat[:, 0], image_id_label_mat[:, 1]))\n",
    "\n",
    "    # Put together train_files, train_labels, test_files and test_labels lists\n",
    "    train_image_ids, test_image_ids = [], []\n",
    "    train_file_paths, test_file_paths = [], []\n",
    "    train_labels, test_labels = [], []\n",
    "    for file_id in image_id_name_map.keys():\n",
    "        file_name = image_id_name_map[file_id]\n",
    "        is_train = image_id_train_test_split_map[file_id]\n",
    "        label = image_id_label_map[file_id] - 1  # To ensure labels start from 0\n",
    "\n",
    "        if is_train:\n",
    "            train_image_ids.append(file_id)\n",
    "            train_file_paths.append(os.path.join(images_data_dir, file_name))\n",
    "            train_labels.append(label)\n",
    "        else:\n",
    "            test_image_ids.append(file_id)\n",
    "            test_file_paths.append(os.path.join(images_data_dir, file_name))\n",
    "            test_labels.append(label)\n",
    "\n",
    "    print (\"Length of test files list\", len(test_file_paths))\n",
    "    print (\"Length of test labels list\", len(test_labels))\n",
    "\n",
    "    return train_image_ids, test_image_ids, train_file_paths, test_file_paths, train_labels, test_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. SRGAN Discriminator Model\n",
    "Source: https://github.com/Lornatang/SRGAN-PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2020 Dakewe Biotech Corporation. All Rights Reserved.\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "#   you may not use this file except in compliance with the License.\n",
    "#   You may obtain a copy of the License at\n",
    "#\n",
    "#       http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ==============================================================================\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    r\"\"\"The main architecture of the discriminator. Similar to VGG structure.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),  # input is (3) x 96 x 96\n",
    "            nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
    "\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=2, padding=1, bias=False),  # state size. (64) x 48 x 48\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
    "\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
    "\n",
    "            nn.Conv2d(128, 128, kernel_size=3, stride=2, padding=1, bias=False),  # state size. (128) x 24 x 24\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
    "\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
    "\n",
    "            nn.Conv2d(256, 256, kernel_size=3, stride=2, padding=1, bias=False),  # state size. (256) x 12 x 12\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
    "\n",
    "            nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
    "\n",
    "            nn.Conv2d(512, 512, kernel_size=3, stride=2, padding=1, bias=False),  # state size. (512) x 6 x 6\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(negative_slope=0.2, inplace=True)\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(512 * 6 * 6, 1024),\n",
    "            nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
    "            nn.Linear(1024, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, input: torch.Tensor) -> torch.Tensor:\n",
    "        out = self.features(input)\n",
    "        out = torch.flatten(out, 1)\n",
    "        out = self.classifier(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "def discriminator() -> Discriminator:\n",
    "    r\"\"\"GAN model architecture from the\n",
    "    `\"One weird trick...\" <https://arxiv.org/abs/1609.04802>`_ paper.\n",
    "    \"\"\"\n",
    "    model = Discriminator()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Evaluation - Quantitative\n",
    "### 3.1 Calculate loss, accuracy, confusion matrix, precision, recall, and F1-score\n",
    "Source:\n",
    "\n",
    "Adjustments: \n",
    "* Added class weights to cross-entropy loss function to address class imbalance\n",
    "* Added confusion matrix, precision, recall, F1, macro-F1, and weighted F1-scores to be printed after every epoch\n",
    "* Return self.network from the train function to be used for GradCAM visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_count_correct_preds(network_output, target):\n",
    "\n",
    "    output = network_output\n",
    "    pred = output.data.max(1, keepdim=True)[1]  # get the index of the max log-probability\n",
    "    pred.data = pred.data.view_as(target.data)\n",
    "    correct = target.eq(pred).sum().item()\n",
    "\n",
    "    return correct\n",
    "\n",
    "class ModelTrainTest():\n",
    "\n",
    "    def __init__(self, network, device, model_file_path, threshold=1e-4):\n",
    "        super(ModelTrainTest, self).__init__()\n",
    "        self.network = network\n",
    "        self.device = device\n",
    "        self.model_file_path = model_file_path\n",
    "        self.threshold = threshold\n",
    "        self.train_loss = 1e9\n",
    "        self.val_loss = 1e9\n",
    "\n",
    "    def train(self, optimizer, epoch, params_max_norm, train_data_loader, val_data_loader):\n",
    "        self.network.train()\n",
    "        train_loss = 0\n",
    "        correct = 0\n",
    "        cnt_batches = 0\n",
    "        \n",
    "        #added class weights\n",
    "        class_weights = torch.FloatTensor([466/5656, 1443/5656, 773/5656, 2658/5656, 316/5656]) #cbb, cbsd, cgm, cmd, healthy\n",
    "        \n",
    "        for batch_idx, (data, target) in enumerate(train_data_loader):\n",
    "            data, target = Variable(data).to(self.device), Variable(target).to(self.device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = self.network(data) \n",
    "            \n",
    "            criterion_weighted = nn.CrossEntropyLoss(weight=class_weights).cuda()\n",
    "            loss = criterion_weighted(output, target)\n",
    "            loss.backward()\n",
    "\n",
    "            clip_grad_norm_(self.network.parameters(), params_max_norm)\n",
    "            optimizer.step()\n",
    "\n",
    "            correct += get_count_correct_preds(output, target)\n",
    "            train_loss += loss.item()\n",
    "            cnt_batches += 1\n",
    "\n",
    "            del data, target, output\n",
    "\n",
    "        train_loss /= cnt_batches\n",
    "        val_loss, val_acc = self.test(epoch, val_data_loader)\n",
    "\n",
    "        if val_loss < self.val_loss - self.threshold:\n",
    "            self.val_loss = val_loss\n",
    "            torch.save(self.network.state_dict(), self.model_file_path)\n",
    "\n",
    "        train_acc = correct / len(train_data_loader.dataset)\n",
    "\n",
    "        print('\\nAfter epoch {} - Train set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "            epoch, train_loss, correct, len(train_data_loader.dataset),\n",
    "            100. * correct / len(train_data_loader.dataset)))\n",
    "\n",
    "        return train_loss, train_acc, val_loss, val_acc, self.network #added self.network for gradCAM visualization\n",
    "\n",
    "    def test(self, epoch, test_data_loader):\n",
    "        self.network.eval()\n",
    "        test_loss = 0\n",
    "        correct = 0\n",
    "\n",
    "        nb_classes = 5\n",
    "\n",
    "        confusion_matrix = torch.zeros(nb_classes, nb_classes)\n",
    "\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (data, target) in enumerate(test_data_loader): \n",
    "                data, target = Variable(data).to(self.device), Variable(target).to(self.device)\n",
    "                output = self.network(data)\n",
    "                test_loss += F.nll_loss(output, target, size_average=False).item()  # sum up batch loss\n",
    "\n",
    "                correct += get_count_correct_preds(output, target)\n",
    "\n",
    "                ##added cf, PR, f1\n",
    "                preds = output.data.max(1, keepdim=True)[1]\n",
    "                for t, p in zip(target.view(-1), preds.view(-1)):\n",
    "                    confusion_matrix[t.long(), p.long()] += 1\n",
    "\n",
    "                del data, target, output\n",
    "        \n",
    "        print(confusion_matrix)\n",
    "        print(confusion_matrix.diag()/confusion_matrix.sum(1))\n",
    "        \n",
    "        cm = confusion_matrix.cpu().data.numpy()\n",
    "        recall = np.diag(cm) / np.sum(cm, axis = 1)\n",
    "        precision = np.diag(cm) / np.sum(cm, axis = 0)\n",
    "        print('recall', recall)\n",
    "        print('precision', precision)\n",
    "\n",
    "        f1 = 2 * precision * recall / (precision + recall)\n",
    "        f1 = np.nan_to_num(f1)\n",
    "        macro_f1 = np.sum(f1)/nb_classes\n",
    "        weighted_f1 = np.sum(np.multiply(f1, np.sum(cm, axis=1)))/np.sum(cm)\n",
    "        print('f1_score', f1)\n",
    "        print('macro_f1', macro_f1)\n",
    "        print('weighted_f1', weighted_f1)\n",
    "        \n",
    "        test_loss /= len(test_data_loader.dataset)\n",
    "        test_acc = correct / len(test_data_loader.dataset)\n",
    "        print('\\nAfter epoch {} - Test set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "            epoch, test_loss, correct, len(test_data_loader.dataset),\n",
    "            100. * correct / len(test_data_loader.dataset)))\n",
    "\n",
    "        return  test_loss, test_acc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Plot loss and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_downstream_loss(train_losses, val_losses, experiment_name):\n",
    "    plt.plot(train_losses)\n",
    "    plt.plot(val_losses)\n",
    "    plt.title('Loss plots')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'val'], loc='upper right')\n",
    "    plt.show()\n",
    "    plt.savefig('classification_loss_{}.jpg'.format(experiment_name))\n",
    "\n",
    "def plot_downstream_accuracy(train_accs, val_accs, experiment_name):\n",
    "    plt.plot(train_accs)\n",
    "    plt.plot(val_accs)\n",
    "    plt.ylim(0.2,1.0)\n",
    "    plt.title('Accuracy plots')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'val'], loc='upper right')\n",
    "    plt.show()\n",
    "    plt.savefig('classification_acc_{}.jpg'.format(experiment_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Save results in csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_display_results(epochs, train_losses, val_losses, train_accs, val_accs, experiment_name):\n",
    "    pd.set_option('display.max_rows', None)\n",
    "\n",
    "    results_df = pd.DataFrame()\n",
    "    results_df['epoch count'] = [i for i in range(1, epochs + 1)]\n",
    "    results_df['train loss'] = train_losses\n",
    "    results_df['val loss'] = val_losses\n",
    "    results_df['train acc'] = train_accs\n",
    "    results_df['val acc'] = val_accs\n",
    "\n",
    "    results_file_path = '{}_observations.csv'.format(experiment_name)\n",
    "    \n",
    "    results_df.to_csv(results_file_path)\n",
    "    display(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Evaluation - Qualitative\n",
    "Grad-CAM Visualization. \n",
    "Source: https://github.com/yaleCat/Grad-CAM-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureExtractor():\n",
    "    \"\"\" Class for extracting activations and \n",
    "    registering gradients from targetted intermediate layers \"\"\"\n",
    "\n",
    "    def __init__(self, model, blob_name, target_layers):\n",
    "        self.model = model\n",
    "        self.blob_name = blob_name\n",
    "        self.target_layers = target_layers\n",
    "        self.gradients = []\n",
    "\n",
    "    def save_gradient(self, grad):\n",
    "        self.gradients.append(grad)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        outputs = []\n",
    "        self.gradients = []\n",
    "        for idx, module in self.model._modules.items():\n",
    "            if idx != self.blob_name:\n",
    "                try:\n",
    "                    x = module(x)\n",
    "                except:\n",
    "                    x = x.view(x.size(0), -1)\n",
    "                    x = module(x)\n",
    "            else:\n",
    "                for name, block in enumerate(getattr(self.model,self.blob_name)):\n",
    "                    x = block(x)\n",
    "                    if str(name) in self.target_layers:\n",
    "                        x.register_hook(self.save_gradient)\n",
    "                        outputs += [x]    \n",
    "        return outputs, x\n",
    "\n",
    "def preprocess_image(img):\n",
    "    means = [0.485, 0.456, 0.406]\n",
    "    stds = [0.229, 0.224, 0.225]\n",
    "\n",
    "    preprocessed_img = img.copy()[:, :, ::-1]\n",
    "    for i in range(3):\n",
    "        preprocessed_img[:, :, i] = preprocessed_img[:, :, i] - means[i]\n",
    "        preprocessed_img[:, :, i] = preprocessed_img[:, :, i] / stds[i]\n",
    "    preprocessed_img = \\\n",
    "        np.ascontiguousarray(np.transpose(preprocessed_img, (2, 0, 1)))\n",
    "    preprocessed_img = torch.from_numpy(preprocessed_img)\n",
    "    preprocessed_img.unsqueeze_(0)\n",
    "    inputs = preprocessed_img.requires_grad_(True)\n",
    "    return inputs\n",
    "\n",
    "def show_cams(img, mask_dic, experiment_name):\n",
    "    for name, mask in mask_dic.items():\n",
    "        show_cam_on_image(img, mask, name, experiment_name)\n",
    "    \n",
    "def show_cam_on_image(img, mask, name, experiment_name):\n",
    "    heatmap = cv2.applyColorMap(np.uint8(255 * mask), cv2.COLORMAP_JET)\n",
    "    heatmap = np.float32(heatmap) / 255\n",
    "    cam = heatmap + np.float32(img)\n",
    "    cam = cam / np.max(cam)\n",
    "    cv2.imwrite(\"cam{}_{}.jpg\".format(name, experiment_name), np.uint8(255 * cam))\n",
    "    plt.imshow(np.uint8(255 * cam)[:,:,::-1])\n",
    "    plt.show()\n",
    "\n",
    "class GradCam:\n",
    "    def __init__(self, model, blob_name, target_layer_names, use_cuda):\n",
    "        self.model = model\n",
    "        self.target_layer_names = target_layer_names\n",
    "        self.model.eval()\n",
    "        self.cuda = use_cuda\n",
    "        if self.cuda:\n",
    "            self.model = model.cuda()\n",
    "        self.extractor = FeatureExtractor(self.model, blob_name, target_layer_names)\n",
    "\n",
    "    def __call__(self, inputs, index=None):\n",
    "        cam_dic = {}\n",
    "        if self.cuda:\n",
    "            features, output = self.extractor(inputs.cuda())\n",
    "        else:\n",
    "            features, output = self.extractor(inputs)\n",
    "\n",
    "        if index == None:\n",
    "            index = np.argmax(output.cpu().data.numpy())\n",
    "        one_hot = np.zeros((1, output.size()[-1]), dtype=np.float32)\n",
    "        one_hot[0][index] = 1\n",
    "        one_hot = torch.from_numpy(one_hot).requires_grad_(True)\n",
    "        if self.cuda:\n",
    "            one_hot = torch.sum(one_hot.cuda() * output)\n",
    "        else:\n",
    "            one_hot = torch.sum(one_hot * output)\n",
    "        self.model.zero_grad()\n",
    "        one_hot.backward()\n",
    "        self.model.zero_grad()\n",
    "        for idx, feature in enumerate(features):\n",
    "            grads_val = self.extractor.gradients[len(features)-1-idx].cpu().data.numpy()\n",
    "            target = features[idx]\n",
    "            target = target.cpu().data.numpy()[0, :]\n",
    "            weights = np.mean(grads_val, axis=(2, 3))[0, :]\n",
    "            cam = np.zeros(target.shape[1:], dtype=np.float32)\n",
    "            for i, w in enumerate(weights):\n",
    "                cam += w * target[i, :, :]\n",
    "            cam = np.maximum(cam, 0)\n",
    "            cam = cv2.resize(cam, (88, 88))\n",
    "            cam = cam - np.min(cam)\n",
    "            cam = cam / np.max(cam)\n",
    "            cam_dic[self.target_layer_names[idx]] = cam\n",
    "        return cam_dic\n",
    "\n",
    "\n",
    "class GuidedBackpropReLU(Function):\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(self, i):\n",
    "        positive_mask = (i > 0).type_as(i)\n",
    "        output = torch.addcmul(torch.zeros(i.size()).type_as(i), i, positive_mask)\n",
    "        self.save_for_backward(i)\n",
    "        return output\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(self, grad_output):\n",
    "        i = self.saved_tensors[0]\n",
    "        grad_input = None\n",
    "        positive_mask_1 = (i > 0).type_as(grad_output)\n",
    "        positive_mask_2 = (grad_output > 0).type_as(grad_output)\n",
    "        grad_input = torch.addcmul(torch.zeros(i.size()).type_as(i),\n",
    "                                   torch.addcmul(torch.zeros(i.size()).type_as(i), grad_output,\n",
    "                                                 positive_mask_1), positive_mask_2)\n",
    "\n",
    "        return grad_input\n",
    "\n",
    "class GuidedBackpropSwish(Function):\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(self, i):\n",
    "        result = i * torch.sigmoid(i)\n",
    "        self.save_for_backward(i)\n",
    "        return result\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(self, grad_output):\n",
    "        i = self.saved_tensors[0]\n",
    "        sigmoid_i = torch.sigmoid(i)\n",
    "        positive_mask_1 = (i > 0).type_as(grad_output)\n",
    "        positive_mask_2 = (grad_output > 0).type_as(grad_output)\n",
    "        grad_input = grad_output * (sigmoid_i * (1 + i * (1 - sigmoid_i))) * positive_mask_1 * positive_mask_2\n",
    "        return grad_input\n",
    "        \n",
    "class GuidedBackpropReLUModel:\n",
    "    def __init__(self, model, use_cuda, activation_layer_name = 'ReLU'):\n",
    "        self.model = model\n",
    "        self.model.eval()\n",
    "        self.cuda = use_cuda\n",
    "        if self.cuda:\n",
    "            self.model = model.cuda()\n",
    "        if activation_layer_name == 'MemoryEfficientSwish':\n",
    "            fb_func = GuidedBackpropSwish.apply\n",
    "        else:\n",
    "            fb_func = GuidedBackpropReLU.apply\n",
    "        for idx0, module0 in self.model._modules.items():\n",
    "            module0 = self.model._modules[idx0]\n",
    "            if module0.__class__.__name__ == activation_layer_name:\n",
    "                self.model._modules[idx0] = fb_func\n",
    "            for idx1, _ in module0._modules.items():\n",
    "                module1 = module0._modules[idx1]\n",
    "                if module1.__class__.__name__ == activation_layer_name:\n",
    "                    self.model._modules[idx0]._modules[idx1] = fb_func\n",
    "                    continue\n",
    "                for idx2, _ in module1._modules.items():\n",
    "                    module2 = module1._modules[idx2]\n",
    "                    if module2.__class__.__name__ == activation_layer_name:\n",
    "                        self.model._modules[idx0]._modules[idx1]._modules[idx2] = fb_func\n",
    "                    \n",
    "    def forward(self, inputs):\n",
    "        return self.model(inputs)\n",
    "\n",
    "    def __call__(self, inputs, index=None):\n",
    "        if self.cuda:\n",
    "            output = self.forward(inputs.cuda())\n",
    "        else:\n",
    "            output = self.forward(inputs)\n",
    "\n",
    "        if index == None:\n",
    "            index = np.argmax(output.cpu().data.numpy())\n",
    "\n",
    "        one_hot = np.zeros((1, output.size()[-1]), dtype=np.float32)\n",
    "        one_hot[0][index] = 1\n",
    "        one_hot = torch.from_numpy(one_hot).requires_grad_(True)\n",
    "        if self.cuda:\n",
    "            one_hot = torch.sum(one_hot.cuda() * output)\n",
    "        else:\n",
    "            one_hot = torch.sum(one_hot * output)\n",
    "        one_hot.backward()\n",
    "        gradient = inputs.grad.cpu().data.numpy()\n",
    "        gradient = gradient[0, :, :, :]\n",
    "        return gradient\n",
    "\n",
    "def deprocess_image(img):\n",
    "    \"\"\" see https://github.com/jacobgil/keras-grad-cam/blob/master/grad-cam.py#L65 \"\"\"\n",
    "    img = img - np.mean(img)\n",
    "    img = img / (np.std(img) + 1e-5)\n",
    "    img = img * 0.1\n",
    "    img = img + 0.5\n",
    "    img = np.clip(img, 0, 1)\n",
    "    return np.uint8(img*255)\n",
    "\n",
    "def show_gbs(inputs, gb_model, target_index, mask_dic, experiment_name):\n",
    "    gb = gb_model(inputs, index=target_index)\n",
    "    gb = gb.transpose((1, 2, 0))\n",
    "    for idx, mask in mask_dic.items():\n",
    "        cam_mask = cv2.merge([mask, mask, mask])\n",
    "        cam_gb = deprocess_image(cam_mask*gb)\n",
    "        cv2.imwrite('cam_gb{}_{}.jpg'.format(idx, experiment_name), cam_gb)\n",
    "    cv2.imwrite('gb_{}.jpg'.format(experiment_name), deprocess_image(gb))\n",
    "    \n",
    "    plt.subplot(1,2,1)\n",
    "    plt.imshow(cam_gb)\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.imshow(deprocess_image(gb))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part B. Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Dataset\n",
    "### 1.1 Data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loading and data discriminators set up\n",
    "train_image_ids, test_image_ids, train_file_paths, test_file_paths, train_labels, test_labels = \\\n",
    "    get_train_test_file_paths_n_labels()\n",
    "\n",
    "# Get validation files and validation labels separate\n",
    "train_image_ids, val_image_ids, train_file_paths, val_file_paths, train_labels, val_labels = \\\n",
    "    split_train_into_train_val(train_image_ids, train_file_paths, train_labels, test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Data augmentations\n",
    "Resize, center crop, horizontal flip, darkness and lightness jitter, rotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data loaders\n",
    "batch_size = 32\n",
    "\n",
    "def_data_transform = transforms.Compose([\n",
    "    transforms.CenterCrop((88, 88)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "hflip_data_transform = transforms.Compose([\n",
    "    transforms.CenterCrop((88, 88)),\n",
    "    transforms.RandomHorizontalFlip(p=1.0),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "darkness_jitter_transform = transforms.Compose([\n",
    "    transforms.CenterCrop((88, 88)),\n",
    "    transforms.ColorJitter(brightness=[0.5, 0.9]),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "lightness_jitter_transform = transforms.Compose([\n",
    "    transforms.CenterCrop((88, 88)),\n",
    "    transforms.ColorJitter(brightness=[1.1, 1.5]),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "rotations_transform = transforms.Compose([\n",
    "    transforms.RandomRotation(degrees=15),\n",
    "    transforms.CenterCrop((88, 88)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "all_in_transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.ColorJitter(brightness=[0.5, 1.5]),\n",
    "    transforms.RandomRotation(degrees=15),\n",
    "    transforms.CenterCrop((88, 88)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_gen = ConcatDataset(\n",
    "        [GetDataset(train_file_paths, train_labels, def_data_transform),\n",
    "         GetDataset(train_file_paths, train_labels, hflip_data_transform),\n",
    "         GetDataset(train_file_paths, train_labels, darkness_jitter_transform),\n",
    "         GetDataset(train_file_paths, train_labels, lightness_jitter_transform),\n",
    "         GetDataset(train_file_paths, train_labels, rotations_transform),\n",
    "         GetDataset(train_file_paths, train_labels, all_in_transform)])\n",
    "train_data_loader = DataLoader(train_data_gen, batch_size = batch_size, shuffle = True, num_workers = 8)\n",
    "\n",
    "val_data_gen = GetDataset(val_file_paths, val_labels, def_data_transform)\n",
    "val_data_loader = DataLoader(val_data_gen, batch_size=batch_size, shuffle=True, num_workers=8)\n",
    "\n",
    "test_data_gen = GetDataset(test_file_paths, test_labels, def_data_transform)\n",
    "test_data_loader = DataLoader(test_data_gen, batch_size=batch_size, shuffle=True, num_workers=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model\n",
    "### 2.1 Load and freeze weights from pretrained network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Discriminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pretrained weights\n",
    "checkpoint = torch.load('../input/srgansrresnetdiscriminator032221/SRGAN_0322.pth')\n",
    "model.load_state_dict(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# examine the architecture\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# freeze weights from pretrained network\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Change classifier for downstream classification\n",
    "Sigmoid is changed to logsoftmax; number of output classes is changed to 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_filters = model.classifier[2].in_features\n",
    "num_classes = 5\n",
    "\n",
    "model.classifier[2] = nn.Linear(num_filters, num_classes)\n",
    "\n",
    "model.classifier[3] = nn.LogSoftmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Experiments\n",
    "The experiments we've run involve image resizing, adjusting the depth of the architecture, and adding dropouts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trial 1: Original SRGAN discriminator\n",
    "Run the original model to create a baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = 'NoResize_Centercrop88'\n",
    "\n",
    "# Set device on which training is done plus optimizer to use\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "epochs = 45\n",
    "lr = 1e-4\n",
    "weight_decay_const = 5e-4\n",
    "optim = 'adam'\n",
    "\n",
    "#deepcopy model\n",
    "model_to_train = copy.deepcopy(model) \n",
    "#move model to cpu; retain model_to_train in gpu\n",
    "model.to('cpu')\n",
    "\n",
    "sgd_optimizer = optim.SGD(model_to_train.parameters(), lr=lr, momentum=0.9, weight_decay=weight_decay_const)\n",
    "adam_optimizer = optim.Adam(model_to_train.parameters(), lr=lr, weight_decay=weight_decay_const)\n",
    "\n",
    "if optim == 'sgd':\n",
    "    optimizer = sgd_optimizer\n",
    "else:\n",
    "    optimizer = adam_optimizer\n",
    "\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', patience=2, verbose=True, min_lr=1e-5)\n",
    "\n",
    "# start training\n",
    "model_file_path = 'cassava_downstream_discriminator_{}.pth'.format(experiment_name)\n",
    "model_train_test_obj = ModelTrainTest(model_to_train, device, model_file_path)\n",
    "train_losses, val_losses, train_accs, val_accs = [], [], [], []\n",
    "\n",
    "print('Training started')\n",
    "for epoch_no in range(epochs):\n",
    "    train_loss, train_acc, val_loss, val_acc, TRAINED_MODEL1 = model_train_test_obj.train(\n",
    "        optimizer=optimizer, epoch=epoch_no, params_max_norm=4,\n",
    "        train_data_loader=train_data_loader, val_data_loader=val_data_loader\n",
    "    )\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    train_accs.append(train_acc)\n",
    "    val_accs.append(val_acc)\n",
    "    scheduler.step(val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_display_results(epochs, train_losses, val_losses, train_accs, val_accs, experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_downstream_loss(train_losses, val_losses, experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_downstream_accuracy(train_accs, val_accs, experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_cam = GradCam(model=TRAINED_MODEL1, blob_name = 'features', target_layer_names=['20'], use_cuda=True)\n",
    "\n",
    "for i in ['train-cbb-68', 'train-cbsd-177', 'train-cmd-180', 'train-healthy-67', 'train-cgm-651']:\n",
    "    print(i)\n",
    "    img = cv2.imread('../input/cassavagradcam/cassava-gradcam/{}.jpg'.format(i), 1)\n",
    "    img = np.float32(cv2.resize(img, (88, 88))) / 255\n",
    "    inputs = preprocess_image(img)\n",
    "\n",
    "    # If None, returns the map for the highest scoring category.\n",
    "    # Otherwise, targets the requested index.\n",
    "    target_index = None\n",
    "    \n",
    "    mask_dic = grad_cam(inputs, target_index)\n",
    "    show_cams(img, mask_dic, '{}_{}'.format(i, experiment_name))\n",
    "    gb_model = GuidedBackpropReLUModel(model=model, activation_layer_name = 'ReLU', use_cuda=True)\n",
    "    show_gbs(inputs, gb_model, target_index, mask_dic, '{}_{}'.format(i, experiment_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trial 2: Resize 256; center crop 88"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resize = transforms.Resize((256, 256))\n",
    "centercrop = transforms.CenterCrop((88, 88))\n",
    "\n",
    "def_data_transform = transforms.Compose([\n",
    "    resize,\n",
    "    centercrop,\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "hflip_data_transform = transforms.Compose([\n",
    "    resize,\n",
    "    centercrop,\n",
    "    transforms.RandomHorizontalFlip(p=1.0),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "darkness_jitter_transform = transforms.Compose([\n",
    "    resize,\n",
    "    centercrop,\n",
    "    transforms.ColorJitter(brightness=[0.5, 0.9]),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "lightness_jitter_transform = transforms.Compose([\n",
    "    resize,\n",
    "    centercrop,\n",
    "    transforms.ColorJitter(brightness=[1.1, 1.5]),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "rotations_transform = transforms.Compose([\n",
    "    resize,\n",
    "    transforms.RandomRotation(degrees=15),\n",
    "    centercrop,\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "all_in_transform = transforms.Compose([\n",
    "    resize,\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.ColorJitter(brightness=[0.5, 1.5]),\n",
    "    transforms.RandomRotation(degrees=15),\n",
    "    centercrop,\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "train_data_gen = ConcatDataset(\n",
    "        [GetDataset(train_file_paths, train_labels, def_data_transform),\n",
    "         GetDataset(train_file_paths, train_labels, hflip_data_transform),\n",
    "         GetDataset(train_file_paths, train_labels, darkness_jitter_transform),\n",
    "         GetDataset(train_file_paths, train_labels, lightness_jitter_transform),\n",
    "         GetDataset(train_file_paths, train_labels, rotations_transform),\n",
    "         GetDataset(train_file_paths, train_labels, all_in_transform)])\n",
    "\n",
    "train_data_loader = DataLoader(train_data_gen, batch_size = batch_size, shuffle = True, num_workers = 8)\n",
    "\n",
    "val_data_gen = GetDataset(val_file_paths, val_labels, def_data_transform)\n",
    "val_data_loader = DataLoader(val_data_gen, batch_size=batch_size, shuffle=True, num_workers=8)\n",
    "\n",
    "test_data_gen = GetDataset(test_file_paths, test_labels, def_data_transform)\n",
    "test_data_loader = DataLoader(test_data_gen, batch_size=batch_size, shuffle=True, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = 'Resize256_Centercrop88'\n",
    "\n",
    "epochs = 45\n",
    "lr = 1e-4\n",
    "weight_decay_const = 5e-4\n",
    "optim = 'adam'\n",
    "\n",
    "model.to('cuda:0')\n",
    "model_to_train = copy.deepcopy(model)\n",
    "model.to('cpu')\n",
    "\n",
    "sgd_optimizer = optim.SGD(model_to_train.parameters(), lr=lr, momentum=0.9, weight_decay=weight_decay_const)\n",
    "adam_optimizer = optim.Adam(model_to_train.parameters(), lr=lr, weight_decay=weight_decay_const)\n",
    "\n",
    "if optim == 'sgd':\n",
    "    optimizer = sgd_optimizer\n",
    "else:\n",
    "    optimizer = adam_optimizer\n",
    "\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', patience=2, verbose=True, min_lr=1e-5)\n",
    "\n",
    "# start training\n",
    "model_file_path = 'cassava_downstream_discriminator_{}.pth'.format(experiment_name)\n",
    "model_train_test_obj = ModelTrainTest(model_to_train, device, model_file_path)\n",
    "train_losses, val_losses, train_accs, val_accs = [], [], [], []\n",
    "\n",
    "print('Training started')\n",
    "for epoch_no in range(epochs):\n",
    "    train_loss, train_acc, val_loss, val_acc, TRAINED_MODEL2 = model_train_test_obj.train(\n",
    "        optimizer=optimizer, epoch=epoch_no, params_max_norm=4,\n",
    "        train_data_loader=train_data_loader, val_data_loader=val_data_loader\n",
    "    )\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    train_accs.append(train_acc)\n",
    "    val_accs.append(val_acc)\n",
    "    scheduler.step(val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_display_results(epochs, train_losses, val_losses, train_accs, val_accs, experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_downstream_loss(train_losses, val_losses, experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_downstream_accuracy(train_accs, val_accs, experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_cam = GradCam(model=TRAINED_MODEL2, blob_name = 'features', target_layer_names=['20'], use_cuda=True)\n",
    "\n",
    "for i in ['train-cbb-68', 'train-cbsd-177', 'train-cmd-180', 'train-healthy-67', 'train-cgm-651']:\n",
    "    print(i)\n",
    "    img = cv2.imread('../input/cassavagradcam/cassava-gradcam/{}.jpg'.format(i), 1)\n",
    "    img = np.float32(cv2.resize(img, (88, 88))) / 255\n",
    "    inputs = preprocess_image(img)\n",
    "\n",
    "    target_index = None\n",
    "    mask_dic = grad_cam(inputs, target_index)\n",
    "    show_cams(img, mask_dic, '{}_{}'.format(i, experiment_name))\n",
    "    gb_model = GuidedBackpropReLUModel(model=model, activation_layer_name = 'ReLU', use_cuda=True)\n",
    "    show_gbs(inputs, gb_model, target_index, mask_dic, '{}_{}'.format(i, experiment_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trial 3: Resize 128; center crop 88"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resize = transforms.Resize((128, 128))\n",
    "centercrop = transforms.CenterCrop((88, 88))\n",
    "\n",
    "def_data_transform = transforms.Compose([\n",
    "    resize,\n",
    "    centercrop,\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "hflip_data_transform = transforms.Compose([\n",
    "    resize,\n",
    "    centercrop,\n",
    "    transforms.RandomHorizontalFlip(p=1.0),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "darkness_jitter_transform = transforms.Compose([\n",
    "    resize,\n",
    "    centercrop,\n",
    "    transforms.ColorJitter(brightness=[0.5, 0.9]),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "lightness_jitter_transform = transforms.Compose([\n",
    "    resize,\n",
    "    centercrop,\n",
    "    transforms.ColorJitter(brightness=[1.1, 1.5]),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "rotations_transform = transforms.Compose([\n",
    "    resize,\n",
    "    transforms.RandomRotation(degrees=15),\n",
    "    centercrop,\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "all_in_transform = transforms.Compose([\n",
    "    resize,\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.ColorJitter(brightness=[0.5, 1.5]),\n",
    "    transforms.RandomRotation(degrees=15),\n",
    "    centercrop,\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "train_data_gen = ConcatDataset(\n",
    "        [GetDataset(train_file_paths, train_labels, def_data_transform),\n",
    "         GetDataset(train_file_paths, train_labels, hflip_data_transform),\n",
    "         GetDataset(train_file_paths, train_labels, darkness_jitter_transform),\n",
    "         GetDataset(train_file_paths, train_labels, lightness_jitter_transform),\n",
    "         GetDataset(train_file_paths, train_labels, rotations_transform),\n",
    "         GetDataset(train_file_paths, train_labels, all_in_transform)])\n",
    "\n",
    "train_data_loader = DataLoader(train_data_gen, batch_size = batch_size, shuffle = True, num_workers = 8)\n",
    "\n",
    "val_data_gen = GetDataset(val_file_paths, val_labels, def_data_transform)\n",
    "val_data_loader = DataLoader(val_data_gen, batch_size=batch_size, shuffle=True, num_workers=8)\n",
    "\n",
    "test_data_gen = GetDataset(test_file_paths, test_labels, def_data_transform)\n",
    "test_data_loader = DataLoader(test_data_gen, batch_size=batch_size, shuffle=True, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = 'Resize128_Centercrop88'\n",
    "\n",
    "epochs = 45\n",
    "lr = 1e-4\n",
    "weight_decay_const = 5e-4\n",
    "optim = 'adam'\n",
    "\n",
    "model.to('cuda:0')\n",
    "model_to_train = copy.deepcopy(model)\n",
    "model.to('cpu')\n",
    "\n",
    "sgd_optimizer = optim.SGD(model_to_train.parameters(), lr=lr, momentum=0.9, weight_decay=weight_decay_const)\n",
    "adam_optimizer = optim.Adam(model_to_train.parameters(), lr=lr, weight_decay=weight_decay_const)\n",
    "\n",
    "if optim == 'sgd':\n",
    "    optimizer = sgd_optimizer\n",
    "else:\n",
    "    optimizer = adam_optimizer\n",
    "\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', patience=2, verbose=True, min_lr=1e-5)\n",
    "\n",
    "# start training\n",
    "model_file_path = 'cassava_downstream_discriminator_{}.pth'.format(experiment_name)\n",
    "model_train_test_obj = ModelTrainTest(model_to_train, device, model_file_path)\n",
    "train_losses, val_losses, train_accs, val_accs = [], [], [], []\n",
    "\n",
    "print('Training started')\n",
    "for epoch_no in range(epochs):\n",
    "    train_loss, train_acc, val_loss, val_acc, TRAINED_MODEL3 = model_train_test_obj.train(\n",
    "        optimizer=optimizer, epoch=epoch_no, params_max_norm=4,\n",
    "        train_data_loader=train_data_loader, val_data_loader=val_data_loader\n",
    "    )\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    train_accs.append(train_acc)\n",
    "    val_accs.append(val_acc)\n",
    "    scheduler.step(val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_display_results(epochs, train_losses, val_losses, train_accs, val_accs, experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_downstream_loss(train_losses, val_losses, experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_downstream_accuracy(train_accs, val_accs, experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_cam = GradCam(model=TRAINED_MODEL3, blob_name = 'features', target_layer_names=['20'], use_cuda=True)\n",
    "\n",
    "for i in ['train-cbb-68', 'train-cbsd-177', 'train-cmd-180', 'train-healthy-67', 'train-cgm-651']:\n",
    "    print(i)\n",
    "    img = cv2.imread('../input/cassavagradcam/cassava-gradcam/{}.jpg'.format(i), 1)\n",
    "    img = np.float32(cv2.resize(img, (88, 88))) / 255\n",
    "    inputs = preprocess_image(img)\n",
    "\n",
    "    target_index = None\n",
    "    mask_dic = grad_cam(inputs, target_index)\n",
    "    show_cams(img, mask_dic, '{}_{}'.format(i, experiment_name))\n",
    "    gb_model = GuidedBackpropReLUModel(model=model, activation_layer_name = 'ReLU', use_cuda=True)\n",
    "    show_gbs(inputs, gb_model, target_index, mask_dic, '{}_{}'.format(i, experiment_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trial 4: Resize 88; no center crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resize = transforms.Resize((88, 88))\n",
    "centercrop = None\n",
    "\n",
    "def_data_transform = transforms.Compose([\n",
    "    resize,\n",
    "    centercrop,\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "hflip_data_transform = transforms.Compose([\n",
    "    resize,\n",
    "    centercrop,\n",
    "    transforms.RandomHorizontalFlip(p=1.0),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "darkness_jitter_transform = transforms.Compose([\n",
    "    resize,\n",
    "    centercrop,\n",
    "    transforms.ColorJitter(brightness=[0.5, 0.9]),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "lightness_jitter_transform = transforms.Compose([\n",
    "    resize,\n",
    "    centercrop,\n",
    "    transforms.ColorJitter(brightness=[1.1, 1.5]),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "rotations_transform = transforms.Compose([\n",
    "    resize,\n",
    "    transforms.RandomRotation(degrees=15),\n",
    "    centercrop,\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "all_in_transform = transforms.Compose([\n",
    "    resize,\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.ColorJitter(brightness=[0.5, 1.5]),\n",
    "    transforms.RandomRotation(degrees=15),\n",
    "    centercrop,\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "train_data_gen = ConcatDataset(\n",
    "        [GetDataset(train_file_paths, train_labels, def_data_transform),\n",
    "         GetDataset(train_file_paths, train_labels, hflip_data_transform),\n",
    "         GetDataset(train_file_paths, train_labels, darkness_jitter_transform),\n",
    "         GetDataset(train_file_paths, train_labels, lightness_jitter_transform),\n",
    "         GetDataset(train_file_paths, train_labels, rotations_transform),\n",
    "         GetDataset(train_file_paths, train_labels, all_in_transform)])\n",
    "\n",
    "train_data_loader = DataLoader(train_data_gen, batch_size = batch_size, shuffle = True, num_workers = 8)\n",
    "\n",
    "val_data_gen = GetDataset(val_file_paths, val_labels, def_data_transform)\n",
    "val_data_loader = DataLoader(val_data_gen, batch_size=batch_size, shuffle=True, num_workers=8)\n",
    "\n",
    "test_data_gen = GetDataset(test_file_paths, test_labels, def_data_transform)\n",
    "test_data_loader = DataLoader(test_data_gen, batch_size=batch_size, shuffle=True, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = 'Resize88_NoCentercrop'\n",
    "\n",
    "epochs = 45\n",
    "lr = 1e-4\n",
    "weight_decay_const = 5e-4\n",
    "optim = 'adam'\n",
    "\n",
    "model.to('cuda:0')\n",
    "model_to_train = copy.deepcopy(model)\n",
    "model.to('cpu')\n",
    "\n",
    "sgd_optimizer = optim.SGD(model_to_train.parameters(), lr=lr, momentum=0.9, weight_decay=weight_decay_const)\n",
    "adam_optimizer = optim.Adam(model_to_train.parameters(), lr=lr, weight_decay=weight_decay_const)\n",
    "\n",
    "if optim == 'sgd':\n",
    "    optimizer = sgd_optimizer\n",
    "else:\n",
    "    optimizer = adam_optimizer\n",
    "\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', patience=2, verbose=True, min_lr=1e-5)\n",
    "\n",
    "# start training\n",
    "model_file_path = 'cassava_downstream_discriminator_{}.pth'.format(experiment_name)\n",
    "model_train_test_obj = ModelTrainTest(model_to_train, device, model_file_path)\n",
    "train_losses, val_losses, train_accs, val_accs = [], [], [], []\n",
    "\n",
    "print('Training started')\n",
    "for epoch_no in range(epochs):\n",
    "    train_loss, train_acc, val_loss, val_acc, TRAINED_MODEL4 = model_train_test_obj.train(\n",
    "        optimizer=optimizer, epoch=epoch_no, params_max_norm=4,\n",
    "        train_data_loader=train_data_loader, val_data_loader=val_data_loader\n",
    "    )\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    train_accs.append(train_acc)\n",
    "    val_accs.append(val_acc)\n",
    "    scheduler.step(val_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_display_results(epochs, train_losses, val_losses, train_accs, val_accs, experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_downstream_loss(train_losses, val_losses, experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_downstream_accuracy(train_accs, val_accs, experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_cam = GradCam(model=TRAINED_MODEL4, blob_name = 'features', target_layer_names=['20'], use_cuda=True)\n",
    "\n",
    "for i in ['train-cbb-68', 'train-cbsd-177', 'train-cmd-180', 'train-healthy-67', 'train-cgm-651']:\n",
    "    print(i)\n",
    "    img = cv2.imread('../input/cassavagradcam/cassava-gradcam/{}.jpg'.format(i), 1)\n",
    "    img = np.float32(cv2.resize(img, (88, 88))) / 255\n",
    "    inputs = preprocess_image(img)\n",
    "\n",
    "    target_index = None\n",
    "    mask_dic = grad_cam(inputs, target_index)\n",
    "    show_cams(img, mask_dic, '{}_{}'.format(i, experiment_name))\n",
    "    gb_model = GuidedBackpropReLUModel(model=model, activation_layer_name = 'ReLU', use_cuda=True)\n",
    "    show_gbs(inputs, gb_model, target_index, mask_dic, '{}_{}'.format(i, experiment_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trial 5: Resize 128; crop 88; remove last convolution block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resize = transforms.Resize((128, 128))\n",
    "centercrop = transforms.CenterCrop((88, 88))\n",
    "\n",
    "def_data_transform = transforms.Compose([\n",
    "    resize,\n",
    "    centercrop,\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "hflip_data_transform = transforms.Compose([\n",
    "    resize,\n",
    "    centercrop,\n",
    "    transforms.RandomHorizontalFlip(p=1.0),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "darkness_jitter_transform = transforms.Compose([\n",
    "    resize,\n",
    "    centercrop,\n",
    "    transforms.ColorJitter(brightness=[0.5, 0.9]),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "lightness_jitter_transform = transforms.Compose([\n",
    "    resize,\n",
    "    centercrop,\n",
    "    transforms.ColorJitter(brightness=[1.1, 1.5]),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "rotations_transform = transforms.Compose([\n",
    "    resize,\n",
    "    transforms.RandomRotation(degrees=15),\n",
    "    centercrop,\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "all_in_transform = transforms.Compose([\n",
    "    resize,\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.ColorJitter(brightness=[0.5, 1.5]),\n",
    "    transforms.RandomRotation(degrees=15),\n",
    "    centercrop,\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "train_data_gen = ConcatDataset(\n",
    "        [GetDataset(train_file_paths, train_labels, def_data_transform),\n",
    "         GetDataset(train_file_paths, train_labels, hflip_data_transform),\n",
    "         GetDataset(train_file_paths, train_labels, darkness_jitter_transform),\n",
    "         GetDataset(train_file_paths, train_labels, lightness_jitter_transform),\n",
    "         GetDataset(train_file_paths, train_labels, rotations_transform),\n",
    "         GetDataset(train_file_paths, train_labels, all_in_transform)])\n",
    "\n",
    "train_data_loader = DataLoader(train_data_gen, batch_size = batch_size, shuffle = True, num_workers = 8)\n",
    "\n",
    "val_data_gen = GetDataset(val_file_paths, val_labels, def_data_transform)\n",
    "val_data_loader = DataLoader(val_data_gen, batch_size=batch_size, shuffle=True, num_workers=8)\n",
    "\n",
    "test_data_gen = GetDataset(test_file_paths, test_labels, def_data_transform)\n",
    "test_data_loader = DataLoader(test_data_gen, batch_size=batch_size, shuffle=True, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = 'Resize128_Centercrop88_Remove1ConvBlock'\n",
    "\n",
    "epochs = 45\n",
    "lr = 1e-4\n",
    "weight_decay_const = 5e-4\n",
    "optim = 'adam'\n",
    "\n",
    "model.to('cuda:0')\n",
    "model_to_train = copy.deepcopy(model)\n",
    "model.to('cpu')\n",
    "\n",
    "sgd_optimizer = optim.SGD(model_to_train.parameters(), lr=lr, momentum=0.9, weight_decay=weight_decay_const)\n",
    "adam_optimizer = optim.Adam(model_to_train.parameters(), lr=lr, weight_decay=weight_decay_const)\n",
    "\n",
    "if optim == 'sgd':\n",
    "    optimizer = sgd_optimizer\n",
    "else:\n",
    "    optimizer = adam_optimizer\n",
    "\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', patience=2, verbose=True, min_lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove last features block (each block consists of Conv2d-BatchNorm2d-LeakyReLU)\n",
    "model_to_train.features = nn.Sequential(*list(model_to_train.features.children())[:-3])\n",
    "\n",
    "# adjust input size to the initial layer of the classifier\n",
    "model_to_train.classifier[0] = nn.Linear(in_features=61952, out_features=1024, bias=True)\n",
    "\n",
    "# inspect the architecture\n",
    "model_to_train.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start training\n",
    "model_file_path = 'cassava_downstream_discriminator_{}.pth'.format(experiment_name)\n",
    "model_train_test_obj2 = ModelTrainTest(model_to_train, device, model_file_path)\n",
    "train_losses, val_losses, train_accs, val_accs = [], [], [], []\n",
    "\n",
    "print('Training started')\n",
    "for epoch_no in range(epochs):\n",
    "    train_loss, train_acc, val_loss, val_acc, TRAINED_MODEL5 = model_train_test_obj2.train(\n",
    "        optimizer=optimizer, epoch=epoch_no, params_max_norm=4,\n",
    "        train_data_loader=train_data_loader, val_data_loader=val_data_loader\n",
    "    )\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    train_accs.append(train_acc)\n",
    "    val_accs.append(val_acc)\n",
    "    scheduler.step(val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_display_results(epochs, train_losses, val_losses, train_accs, val_accs, experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_downstream_loss(train_losses, val_losses, experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_downstream_accuracy(train_accs, val_accs, experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_cam = GradCam(model=TRAINED_MODEL5, blob_name = 'features', target_layer_names=['20'], use_cuda=True)\n",
    "\n",
    "for i in ['train-cbb-68', 'train-cbsd-177', 'train-cmd-180', 'train-healthy-67', 'train-cgm-651']:\n",
    "    print(i)\n",
    "    img = cv2.imread('../input/cassavagradcam/cassava-gradcam/{}.jpg'.format(i), 1)\n",
    "    img = np.float32(cv2.resize(img, (88, 88))) / 255\n",
    "    inputs = preprocess_image(img)\n",
    "\n",
    "    target_index = None\n",
    "    mask_dic = grad_cam(inputs, target_index)\n",
    "    show_cams(img, mask_dic, '{}_{}'.format(i, experiment_name))\n",
    "    gb_model = GuidedBackpropReLUModel(model=model, activation_layer_name = 'ReLU', use_cuda=True)\n",
    "    show_gbs(inputs, gb_model, target_index, mask_dic, '{}_{}'.format(i, experiment_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trial 6: Resize 128; crop 88; remove last 2 convolution blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = 'Resize128_Centercrop88_Remove2ConvBlocks'\n",
    "\n",
    "epochs = 45\n",
    "lr = 1e-4\n",
    "weight_decay_const = 5e-4\n",
    "optim = 'adam'\n",
    "\n",
    "model.to('cuda:0')\n",
    "model_to_train = copy.deepcopy(model)\n",
    "model.to('cpu')\n",
    "\n",
    "model_to_train.to(device)\n",
    "sgd_optimizer = optim.SGD(model_to_train.parameters(), lr=lr, momentum=0.9, weight_decay=weight_decay_const)\n",
    "adam_optimizer = optim.Adam(model_to_train.parameters(), lr=lr, weight_decay=weight_decay_const)\n",
    "\n",
    "if optim == 'sgd':\n",
    "    optimizer = sgd_optimizer\n",
    "else:\n",
    "    optimizer = adam_optimizer\n",
    "\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', patience=2, verbose=True, min_lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove last 2 features block (each block consists of Conv2d-BatchNorm2d-LeakyReLU)\n",
    "model_to_train.features = nn.Sequential(*list(model_to_train.features.children())[:-3])\n",
    "model_to_train.features = nn.Sequential(*list(model_to_train.features.children())[:-3])\n",
    "\n",
    "# adjust input size to the initial layer of the classifier\n",
    "model_to_train.classifier[0] = nn.Linear(in_features=30976, out_features=1024, bias=True)\n",
    "\n",
    "# inspect the architecture\n",
    "model_to_train.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start training\n",
    "model_file_path = 'cassava_downstream_discriminator_{}.pth'.format(experiment_name)\n",
    "model_train_test_obj2 = ModelTrainTest(model_to_train, device, model_file_path)\n",
    "train_losses, val_losses, train_accs, val_accs = [], [], [], []\n",
    "\n",
    "print('Training started')\n",
    "for epoch_no in range(epochs):\n",
    "    train_loss, train_acc, val_loss, val_acc, TRAINED_MODEL6 = model_train_test_obj2.train(\n",
    "        optimizer=optimizer, epoch=epoch_no, params_max_norm=4,\n",
    "        train_data_loader=train_data_loader, val_data_loader=val_data_loader\n",
    "    )\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    train_accs.append(train_acc)\n",
    "    val_accs.append(val_acc)\n",
    "    scheduler.step(val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_display_results(epochs, train_losses, val_losses, train_accs, val_accs, experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_downstream_loss(train_losses, val_losses, experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_downstream_accuracy(train_accs, val_accs, experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_cam = GradCam(model=TRAINED_MODEL6, blob_name = 'features', target_layer_names=['20'], use_cuda=True)\n",
    "\n",
    "for i in ['train-cbb-68', 'train-cbsd-177', 'train-cmd-180', 'train-healthy-67', 'train-cgm-651']:\n",
    "    print(i)\n",
    "    img = cv2.imread('../input/cassavagradcam/cassava-gradcam/{}.jpg'.format(i), 1)\n",
    "    img = np.float32(cv2.resize(img, (88, 88))) / 255\n",
    "    inputs = preprocess_image(img)\n",
    "\n",
    "    target_index = None\n",
    "    mask_dic = grad_cam(inputs, target_index)\n",
    "    show_cams(img, mask_dic, '{}_{}'.format(i, experiment_name))\n",
    "    gb_model = GuidedBackpropReLUModel(model=model, activation_layer_name = 'ReLU', use_cuda=True)\n",
    "    show_gbs(inputs, gb_model, target_index, mask_dic, '{}_{}'.format(i, experiment_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trial 7: Resize 128; crop 88; remove last 3 convolution blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = 'Resize128_Centercrop88_Remove3ConvBlocks'\n",
    "\n",
    "epochs = 45\n",
    "lr = 1e-4\n",
    "weight_decay_const = 5e-4\n",
    "optim = 'adam'\n",
    "\n",
    "model.to('cuda:0')\n",
    "model_to_train = copy.deepcopy(model)\n",
    "model.to('cpu')\n",
    "\n",
    "model_to_train.to(device)\n",
    "sgd_optimizer = optim.SGD(model_to_train.parameters(), lr=lr, momentum=0.9, weight_decay=weight_decay_const)\n",
    "adam_optimizer = optim.Adam(model_to_train.parameters(), lr=lr, weight_decay=weight_decay_const)\n",
    "\n",
    "if optim == 'sgd':\n",
    "    optimizer = sgd_optimizer\n",
    "else:\n",
    "    optimizer = adam_optimizer\n",
    "\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', patience=2, verbose=True, min_lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove last 3 features block (each block consists of Conv2d-BatchNorm2d-LeakyReLU)\n",
    "model_to_train.features = nn.Sequential(*list(model_to_train.features.children())[:-3])\n",
    "model_to_train.features = nn.Sequential(*list(model_to_train.features.children())[:-3])\n",
    "model_to_train.features = nn.Sequential(*list(model_to_train.features.children())[:-3])\n",
    "\n",
    "# adjust input size to the initial layer of the classifier\n",
    "model_to_train.classifier[0] = nn.Linear(in_features=256*22*22, out_features=1024, bias=True)\n",
    "\n",
    "# inspect the architecture\n",
    "model_to_train.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start training\n",
    "model_file_path = 'cassava_downstream_discriminator_{}.pth'.format(experiment_name)\n",
    "model_train_test_obj2 = ModelTrainTest(model_to_train, device, model_file_path)\n",
    "train_losses, val_losses, train_accs, val_accs = [], [], [], []\n",
    "\n",
    "print('Training started')\n",
    "for epoch_no in range(epochs):\n",
    "    train_loss, train_acc, val_loss, val_acc, TRAINED_MODEL7 = model_train_test_obj2.train(\n",
    "        optimizer=optimizer, epoch=epoch_no, params_max_norm=4,\n",
    "        train_data_loader=train_data_loader, val_data_loader=val_data_loader\n",
    "    )\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    train_accs.append(train_acc)\n",
    "    val_accs.append(val_acc)\n",
    "    scheduler.step(val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_display_results(epochs, train_losses, val_losses, train_accs, val_accs, experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_downstream_loss(train_losses, val_losses, experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_downstream_accuracy(train_accs, val_accs, experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_cam = GradCam(model=TRAINED_MODEL7, blob_name = 'features', target_layer_names=['20'], use_cuda=True)\n",
    "\n",
    "for i in ['train-cbb-68', 'train-cbsd-177', 'train-cmd-180', 'train-healthy-67', 'train-cgm-651']:\n",
    "    print(i)\n",
    "    img = cv2.imread('../input/cassavagradcam/cassava-gradcam/{}.jpg'.format(i), 1)\n",
    "    img = np.float32(cv2.resize(img, (88, 88))) / 255\n",
    "    inputs = preprocess_image(img)\n",
    "\n",
    "    target_index = None\n",
    "    mask_dic = grad_cam(inputs, target_index)\n",
    "    show_cams(img, mask_dic, '{}_{}'.format(i, experiment_name))\n",
    "    gb_model = GuidedBackpropReLUModel(model=model, activation_layer_name = 'ReLU', use_cuda=True)\n",
    "    show_gbs(inputs, gb_model, target_index, mask_dic, '{}_{}'.format(i, experiment_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trial 8: Resize 128; center crop 88; remove last conv block; dropout p=0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = 'Resize128_Centercrop88_Dropout05'\n",
    "\n",
    "epochs = 45\n",
    "lr = 1e-4\n",
    "weight_decay_const = 5e-4\n",
    "optim = 'adam'\n",
    "\n",
    "model.to('cuda:0')\n",
    "model_to_train = copy.deepcopy(model)\n",
    "model.to('cpu')\n",
    "\n",
    "sgd_optimizer = optim.SGD(model_to_train.parameters(), lr=lr, momentum=0.9, weight_decay=weight_decay_const)\n",
    "adam_optimizer = optim.Adam(model_to_train.parameters(), lr=lr, weight_decay=weight_decay_const)\n",
    "\n",
    "if optim == 'sgd':\n",
    "    optimizer = sgd_optimizer\n",
    "else:\n",
    "    optimizer = adam_optimizer\n",
    "\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', patience=2, verbose=True, min_lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove last features block (each block consists of Conv2d-BatchNorm2d-LeakyReLU)\n",
    "model_to_train.features = nn.Sequential(*list(model_to_train.features.children())[:-3])\n",
    "\n",
    "# adjust input size to the initial layer of the classifier\n",
    "model_to_train.classifier[0] = nn.Linear(in_features=61952, out_features=1024, bias=True)\n",
    "\n",
    "# add dropout after leaky ReLU\n",
    "model.classifier[1] = nn.Sequential(nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
    "                                   nn.Dropout(p=0.5,inplace=False))\n",
    "\n",
    "# inspect the architecture\n",
    "model_to_train.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start training\n",
    "model_file_path = 'cassava_downstream_discriminator_{}.pth'.format(experiment_name)\n",
    "model_train_test_obj = ModelTrainTest(model_to_train, device, model_file_path)\n",
    "train_losses, val_losses, train_accs, val_accs = [], [], [], []\n",
    "\n",
    "print('Training started')\n",
    "for epoch_no in range(epochs):\n",
    "    train_loss, train_acc, val_loss, val_acc, TRAINED_MODEL9 = model_train_test_obj.train(\n",
    "        optimizer=optimizer, epoch=epoch_no, params_max_norm=4,\n",
    "        train_data_loader=train_data_loader, val_data_loader=val_data_loader\n",
    "    )\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    train_accs.append(train_acc)\n",
    "    val_accs.append(val_acc)\n",
    "    scheduler.step(val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_display_results(epochs, train_losses, val_losses, train_accs, val_accs, experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_downstream_loss(train_losses, val_losses, experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_downstream_accuracy(train_accs, val_accs, experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_cam = GradCam(model=TRAINED_MODEL9, blob_name = 'features', target_layer_names=['20'], use_cuda=True)\n",
    "\n",
    "for i in ['train-cbb-68', 'train-cbsd-177', 'train-cmd-180', 'train-healthy-67', 'train-cgm-651']:\n",
    "    print(i)\n",
    "    img = cv2.imread('../input/cassavagradcam/cassava-gradcam/{}.jpg'.format(i), 1)\n",
    "    img = np.float32(cv2.resize(img, (88, 88))) / 255\n",
    "    inputs = preprocess_image(img)\n",
    "\n",
    "    target_index = None\n",
    "    mask_dic = grad_cam(inputs, target_index)\n",
    "    show_cams(img, mask_dic, '{}_{}'.format(i, experiment_name))\n",
    "    gb_model = GuidedBackpropReLUModel(model=model, activation_layer_name = 'ReLU', use_cuda=True)\n",
    "    show_gbs(inputs, gb_model, target_index, mask_dic, '{}_{}'.format(i, experiment_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trial 10: Resize 128; center crop 88; remove last conv block; dropout p=0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = 'Resize128_Centercrop88_Dropout07'\n",
    "\n",
    "epochs = 45\n",
    "lr = 1e-4\n",
    "weight_decay_const = 5e-4\n",
    "optim = 'adam'\n",
    "\n",
    "model.to('cuda:0')\n",
    "model_to_train = copy.deepcopy(model)\n",
    "model.to('cpu')\n",
    "\n",
    "sgd_optimizer = optim.SGD(model_to_train.parameters(), lr=lr, momentum=0.9, weight_decay=weight_decay_const)\n",
    "adam_optimizer = optim.Adam(model_to_train.parameters(), lr=lr, weight_decay=weight_decay_const)\n",
    "\n",
    "if optim == 'sgd':\n",
    "    optimizer = sgd_optimizer\n",
    "else:\n",
    "    optimizer = adam_optimizer\n",
    "\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', patience=2, verbose=True, min_lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove last features block (each block consists of Conv2d-BatchNorm2d-LeakyReLU)\n",
    "model_to_train.features = nn.Sequential(*list(model_to_train.features.children())[:-3])\n",
    "\n",
    "# adjust input size to the initial layer of the classifier\n",
    "model_to_train.classifier[0] = nn.Linear(in_features=61952, out_features=1024, bias=True)\n",
    "\n",
    "# add dropout after leaky ReLU\n",
    "model.classifier[1] = nn.Sequential(nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
    "                                   nn.Dropout(p=0.7,inplace=False))\n",
    "\n",
    "# inspect the architecture\n",
    "model_to_train.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start training\n",
    "model_file_path = 'cassava_downstream_discriminator_{}.pth'.format(experiment_name)\n",
    "model_train_test_obj = ModelTrainTest(model_to_train, device, model_file_path)\n",
    "train_losses, val_losses, train_accs, val_accs = [], [], [], []\n",
    "\n",
    "print('Training started')\n",
    "for epoch_no in range(epochs):\n",
    "    train_loss, train_acc, val_loss, val_acc, TRAINED_MODEL10 = model_train_test_obj.train(\n",
    "        optimizer=optimizer, epoch=epoch_no, params_max_norm=4,\n",
    "        train_data_loader=train_data_loader, val_data_loader=val_data_loader\n",
    "    )\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    train_accs.append(train_acc)\n",
    "    val_accs.append(val_acc)\n",
    "    scheduler.step(val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_display_results(epochs, train_losses, val_losses, train_accs, val_accs, experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_downstream_loss(train_losses, val_losses, experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_downstream_accuracy(train_accs, val_accs, experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_cam = GradCam(model=TRAINED_MODEL10, blob_name = 'features', target_layer_names=['20'], use_cuda=True)\n",
    "\n",
    "for i in ['train-cbb-68', 'train-cbsd-177', 'train-cmd-180', 'train-healthy-67', 'train-cgm-651']:\n",
    "    print(i)\n",
    "    img = cv2.imread('../input/cassavagradcam/cassava-gradcam/{}.jpg'.format(i), 1)\n",
    "    img = np.float32(cv2.resize(img, (88, 88))) / 255\n",
    "    inputs = preprocess_image(img)\n",
    "\n",
    "    target_index = None\n",
    "    mask_dic = grad_cam(inputs, target_index)\n",
    "    show_cams(img, mask_dic, '{}_{}'.format(i, experiment_name))\n",
    "    gb_model = GuidedBackpropReLUModel(model=model, activation_layer_name = 'ReLU', use_cuda=True)\n",
    "    show_gbs(inputs, gb_model, target_index, mask_dic, '{}_{}'.format(i, experiment_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trial 11: Resize 128; center crop 88; remove last conv block; dropout p=0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = 'Resize128_Centercrop88_Dropout09'\n",
    "\n",
    "epochs = 45\n",
    "lr = 1e-4\n",
    "weight_decay_const = 5e-4\n",
    "optim = 'adam'\n",
    "\n",
    "model.to('cuda:0')\n",
    "model_to_train = copy.deepcopy(model)\n",
    "model.to('cpu')\n",
    "\n",
    "sgd_optimizer = optim.SGD(model_to_train.parameters(), lr=lr, momentum=0.9, weight_decay=weight_decay_const)\n",
    "adam_optimizer = optim.Adam(model_to_train.parameters(), lr=lr, weight_decay=weight_decay_const)\n",
    "\n",
    "if optim == 'sgd':\n",
    "    optimizer = sgd_optimizer\n",
    "else:\n",
    "    optimizer = adam_optimizer\n",
    "\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', patience=2, verbose=True, min_lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove last features block (each block consists of Conv2d-BatchNorm2d-LeakyReLU)\n",
    "model_to_train.features = nn.Sequential(*list(model_to_train.features.children())[:-3])\n",
    "\n",
    "# adjust input size to the initial layer of the classifier\n",
    "model_to_train.classifier[0] = nn.Linear(in_features=61952, out_features=1024, bias=True)\n",
    "\n",
    "# add dropout after leaky ReLU\n",
    "model.classifier[1] = nn.Sequential(nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
    "                                   nn.Dropout(p=0.9,inplace=False))\n",
    "\n",
    "# inspect the architecture\n",
    "model_to_train.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start training\n",
    "model_file_path = 'cassava_downstream_discriminator_{}.pth'.format(experiment_name)\n",
    "model_train_test_obj = ModelTrainTest(model_to_train, device, model_file_path)\n",
    "train_losses, val_losses, train_accs, val_accs = [], [], [], []\n",
    "\n",
    "print('Training started')\n",
    "for epoch_no in range(epochs):\n",
    "    train_loss, train_acc, val_loss, val_acc, TRAINED_MODEL10 = model_train_test_obj.train(\n",
    "        optimizer=optimizer, epoch=epoch_no, params_max_norm=4,\n",
    "        train_data_loader=train_data_loader, val_data_loader=val_data_loader\n",
    "    )\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    train_accs.append(train_acc)\n",
    "    val_accs.append(val_acc)\n",
    "    scheduler.step(val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_display_results(epochs, train_losses, val_losses, train_accs, val_accs, experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_downstream_loss(train_losses, val_losses, experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_downstream_accuracy(train_accs, val_accs, experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_cam = GradCam(model=TRAINED_MODEL11, blob_name = 'features', target_layer_names=['20'], use_cuda=True)\n",
    "\n",
    "for i in ['train-cbb-68', 'train-cbsd-177', 'train-cmd-180', 'train-healthy-67', 'train-cgm-651']:\n",
    "    print(i)\n",
    "    img = cv2.imread('../input/cassavagradcam/cassava-gradcam/{}.jpg'.format(i), 1)\n",
    "    img = np.float32(cv2.resize(img, (88, 88))) / 255\n",
    "    inputs = preprocess_image(img)\n",
    "\n",
    "    target_index = None\n",
    "    mask_dic = grad_cam(inputs, target_index)\n",
    "    show_cams(img, mask_dic, '{}_{}'.format(i, experiment_name))\n",
    "    gb_model = GuidedBackpropReLUModel(model=model, activation_layer_name = 'ReLU', use_cuda=True)\n",
    "    show_gbs(inputs, gb_model, target_index, mask_dic, '{}_{}'.format(i, experiment_name))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
